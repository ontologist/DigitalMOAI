# WittyHead MASST Paper v3 - Final Corrections

**Date**: 2025-10-14
**Version**: v3 (Corrected)
**Status**: Ready for Submission

---

## Updates Applied

### Author Information Corrections

**Previous (INCORRECT)**:
- Email: yuri.tijerino@kwansei.ac.jp
- Affiliation: School of Science and Technology

**Current (CORRECT)**:
- Email: ontologist@kwansei.ac.jp
- Affiliation: Intelligent Blockchain+ Innovation Research Center

### Files Updated

1. **`wittyhead-masst-paper-v3-empathetic.tex`** (Lines 18-22)
   - Updated author block with correct email and affiliation
   - All other content remains unchanged from v3

2. **`wittyhead-masst-empathetic-final-corrected.zip`** (81 KB)
   - Contains corrected .tex file
   - IEEEtran.cls (IEEE LaTeX class)
   - references-v3.bib (26 validated citations)
   - Ready for Overleaf upload

---

## Submission Package Contents

**Package**: `wittyhead-masst-empathetic-final-corrected.zip`

**Files Included**:
1. `wittyhead-masst-paper-v3-empathetic.tex` - Main paper (3,563 words, ~4 pages)
2. `IEEEtran.cls` - IEEE LaTeX class file v1.8b
3. `references-v3.bib` - Bibliography with 26 entries

**To Use**:
1. Upload zip file to Overleaf.com
2. Set main document: `wittyhead-masst-paper-v3-empathetic.tex`
3. Compile with LaTeX or pdfLaTeX
4. Review compiled PDF
5. Submit to MASST workshop

---

## Paper Details (Unchanged from v3)

**Title**: WittyHead: A Multi-Modal Architecture for Empathetic Human-Agent Collaboration Through Emotional Expressivity

**Author**: Yuri A. Tijerino
**Email**: ontologist@kwansei.ac.jp
**Affiliation**: Kwansei Gakuin University, Intelligent Blockchain+ Innovation Research Center

**Word Count**: 3,563 words
**Estimated Length**: ~4 pages (IEEE double-column format)
**References**: 26 citations (all validated)
**Fabricated Data**: NONE - 100% research-grounded

---

## Key Features (Summary)

### 1. Empathetic (Non-Mirroring) Architecture
- Based on Gilbert et al. (2019) research
- User sad → Avatar compassionate concern (NOT mirrored sadness)
- User angry → Avatar calm concern (de-escalation)

### 2. Multi-Modal Coordination
- **Facial**: FACS-validated ARKit blendshapes
- **Gaze**: 60-90% eye contact (therapeutic alliance)
- **Gesture**: Prosodic-aligned (Loehr 2012)
- **Voice**: Prosody modulation (Scherer 2003)

### 3. Supporting Vulnerable Populations
- Social isolation (foster care youth, elderly, refugees)
- Mental health (depression, anxiety, trauma)
- Disability (visual, auditory, motor, cognitive)
- Cultural sensitivity (Easy Japanese, cultural ontologies)

### 4. Digital MOAI Integration
- Privacy-preserving local-first emotion processing
- User-controlled automation levels
- Group-aware MOAI collective context
- Emergency coordinated distress response

---

## MASST Initiative Alignment

### 1. Context-Aware Behavioral Guard Rails
- Ontology-driven emotion validation
- Medical ontologies block inappropriate celebrations
- Empathetic response mappings prevent invalidating mirroring

### 2. Mutual Observability
- Explainable multi-modal reasoning
- System logs: "User: Sad (0.8) → Avatar: Compassionate Concern (75% eye contact, palm-up gestures)"
- Reasoning traces enable human oversight

### 3. Design-Time Risk Mitigation
- Therapeutic alliance research integration
- Validated emotion mappings prevent empathy failures
- FACS-validated expressions avoid uncanny valley

---

## Citations (26 Total)

### From MASST Abstract Document
- Christiano et al. (2017) - RLHF
- WCAG 2.1 (2018) - Accessibility
- Miyazaki (2017, 2007) - Disability studies, Easy Japanese
- Matsuura et al. (2022) - Easy Japanese effectiveness
- Satoh (1995) - Easy Japanese for disasters
- Kotoku & Tijerino (2021) - AI in nursing
- FASTER H2020 (2019-2022) - AIngle DLT
- Buettner (2008) - Blue Zones & MOAI
- Suzuki et al. (2001) - Okinawan longevity

### From WittyHead Research Repository
- Gilbert et al. (2019) - Compassionate faces
- McEwan et al. (2014) - Compassionate vs. critical expressions
- Ekman & Friesen (1978) - FACS
- Dowell & Berman (1994) - Therapeutic alliance
- Adams & Kleck (2005) - Gaze and emotion perception
- Bradley et al. (2008) - Pupillometry
- Vertegaal et al. (2001) - Gaze turn-taking
- Loehr (2012) - Gesture-prosody synchrony
- Pease & Pease (2006) - Palm orientation
- McNeill (1992) - Hand gesture types
- Scherer (2003) - Vocal emotion communication
- Sonnby-Borgström (2009) - Facial mimicry and empathy
- Choi et al. (2023) - Virtual counselors
- Serengil & Ozpinar (2020) - LightFace/DeepFace

---

## Next Steps

1. ✅ **Paper corrected** with proper email and affiliation
2. ✅ **Package created** - `wittyhead-masst-empathetic-final-corrected.zip`
3. ⏳ **Upload to Overleaf** - User action required
4. ⏳ **Compile and verify** - Check formatting in compiled PDF
5. ⏳ **Final review** - Proofread compiled output
6. ⏳ **Submit to MASST** - Workshop submission portal

---

## Changelog from v3 (Original)

**Line 19-22**: Updated author affiliation block
- OLD: `School of Science and Technology` / `yuri.tijerino@kwansei.ac.jp`
- NEW: `Intelligent Blockchain+ Innovation Research Center` / `ontologist@kwansei.ac.jp`

**All other content**: Unchanged

---

*Final corrections completed: 2025-10-14*
*Author: Yuri A. Tijerino*
*Affiliation: Kwansei Gakuin University, Intelligent Blockchain+ Innovation Research Center*
*Email: ontologist@kwansei.ac.jp*
