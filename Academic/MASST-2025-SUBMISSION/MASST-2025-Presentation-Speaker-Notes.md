# Digital MOAI: Presentation Speaker Notes
# デジタル模合：プレゼンテーション発表者ノート

**A Story-Driven Narrative Journey**
**ストーリー駆動のナラティブジャーニー**

---

## Slide 1: Title - Opening the Door

**Speaker Notes (English):**

"Good morning. Before I tell you about our research, I want to tell you about a night that changed everything.

It's 11:47 PM in Tokyo. In a small apartment in Setagaya ward, a 74-year-old man named Haruto wakes up with chest pains. His wife passed away two years ago. His children live in Osaka. He's alone.

This presentation isn't about technology. It's about whether Haruto lives or dies. It's about whether artificial intelligence can save lives—or whether it will fail the people who need it most.

I'm Yuri Tijerino from Kwansei Gakuin University, and along with my colleagues Kazuko Kotoku from Fukuoka University and Yasushi Miyazaki, we've been asking one question: How do we build AI systems for the most vulnerable people in our society?

The answer surprised us. It wasn't in Silicon Valley. It wasn't in cutting-edge neural networks. It was in Okinawa, in a tradition that's kept people alive for 500 years."

**発表者ノート（日本語）:**

「おはようございます。私たちの研究についてお話しする前に、すべてを変えた一晩のことをお話ししたいと思います。

東京、午後11時47分。世田谷区の小さなアパートで、田中ハルトという74歳の男性が胸の痛みで目を覚まします。妻は2年前に他界しました。子供たちは大阪に住んでいます。彼は一人です。

このプレゼンテーションは技術についてではありません。ハルトが生きるか死ぬかについてです。人工知能が命を救えるのか、それとも最も必要としている人々を失望させるのか、についてです。

私は関西学院大学のティヘリノ　ジュリです。福岡大学の神徳和子教授、そして宮崎康教授と共に、一つの問いを追求してきました：最も脆弱な人々のためのAIシステムをどう構築するか？

答えは私たちを驚かせました。それはシリコンバレーにはありませんでした。最先端のニューラルネットワークでもありませんでした。それは沖縄にありました。500年間人々を生かし続けてきた伝統の中に。」

---

## Slide 2: Meet Haruto - The Crisis Unfolds

**Speaker Notes (English):**

"Let me take you back to that night. Haruto is sitting at his kitchen table. The pain is getting worse. He knows he should call an ambulance, but he's confused, afraid. What if it's nothing? What if he's overreacting?

In that moment of hesitation, seconds become minutes. Minutes can become tragedy.

But Haruto has something most 74-year-old men living alone don't have. On his smartphone, there's an app. A simple button that says 'Emergency.' His hand shaking, he taps it.

What happens next is not magic. It's not science fiction. It's what happens when you design AI with one principle above all others: human dignity.

Within 2 seconds, four people are notified. Keiko, his neighbor, gets an alert. She lives 5 minutes away. The AI has already pulled Haruto's medical records—his heart condition, his medications, his allergies. The ambulance is on its way. By the time the paramedics arrive, Keiko is holding Haruto's hand, and his complete medical history is on a tablet, ready.

Haruto survives. But millions of people like Haruto—elderly, disabled, isolated, vulnerable—don't have this. And current AI systems are failing them catastrophically."

**発表者ノート（日本語）:**

「あの夜に戻りましょう。ハルトはキッチンテーブルに座っています。痛みはひどくなっています。救急車を呼ぶべきだとわかっていますが、混乱し、怯えています。何でもなかったら？大げさに反応しているだけだったら？

そのためらいの瞬間、秒が分になります。分は悲劇になる可能性があります。

しかし、ハルトには一人暮らしの74歳の男性のほとんどが持っていないものがあります。スマートフォンに、アプリがあります。「緊急」と書かれたシンプルなボタン。震える手で、彼はそれをタップします。

次に起こることは魔法ではありません。SF でもありません。他のすべての原則より一つの原則、つまり人間の尊厳を重視してAIを設計したときに起こることです。

2秒以内に、4人が通知されます。隣人の恵子さんにアラートが届きます。彼女は5分のところに住んでいます。AIはすでにハルトの医療記録—心臓の状態、薬、アレルギー—を引き出しています。救急車が向かっています。救急隊員が到着するまでに、恵子さんはハルトの手を握り、彼の完全な病歴がタブレットに準備されています。

ハルトは生き延びます。しかし、ハルトのような何百万もの人々—高齢者、障害者、孤立した人々、脆弱な人々—はこれを持っていません。そして現在のAIシステムは彼らを壊滅的に失望させています。」

---

## Slide 3: The Problem - When AI Fails

**Speaker Notes (English):**

"Haruto's story has a happy ending. But let me tell you about Sora.

Sora is 25 years old, undocumented, working two jobs in Tokyo to send money home. When her landlord discovers she's undocumented, she's evicted. She needs help desperately. But every system that could help her requires centralized data. Immigration status. Bank records. Employment history.

For Sora, using those systems means deportation. So she sleeps in internet cafes. She doesn't seek help. The AI systems designed to 'help' people like Sora become weapons against her.

Or consider Sakura, a 31-year-old transgender woman. A data breach exposes her medical records, her deadname, her transition history. She faces violence. Discrimination. Housing rejection.

Or Yui, 22, who has been isolated in her room for two years. Social anxiety so severe she can't open her door. Every well-meaning AI chatbot that says 'just reach out!' doesn't understand that for Yui, reaching out feels like jumping off a cliff.

Current AI systems fail these people because they were designed for average users in average situations. They prioritize efficiency over safety. They centralize data, creating honeypots for hackers and governments. They lack cultural awareness, accessibility, human oversight.

For vulnerable populations, these aren't bugs. They're existential threats. AI failures aren't inconveniences—they're catastrophes."

**発表者ノート（日本語）:**

「ハルトの物語はハッピーエンドです。でも、ソラのことをお話しさせてください。

ソラは25歳、非正規滞在者で、東京で二つの仕事をして実家に送金しています。家主が彼女が非正規滞在者であることを知ると、彼女は追い出されます。彼女は必死に助けを必要としています。しかし、彼女を助けることができるすべてのシステムは集中型データを必要とします。移民ステータス。銀行記録。雇用履歴。

ソラにとって、これらのシステムを使うことは国外退去を意味します。だから彼女はインターネットカフェで寝ます。助けを求めません。ソラのような人々を「助ける」ために設計されたAIシステムは、彼女に対する武器になります。

あるいは、31歳のトランスジェンダー女性、サクラを考えてください。データ漏洩が彼女の医療記録、旧名、移行履歴を暴露します。彼女は暴力に直面します。差別。住宅拒否。

あるいは、22歳のユイ。2年間部屋に閉じこもっています。社交不安がひどく、ドアを開けることができません。「連絡を取ってください！」と言う善意のAIチャットボットはすべて、ユイにとって連絡を取ることが崖から飛び降りるように感じることを理解していません。

現在のAIシステムがこれらの人々を失望させるのは、平均的なユーザーの平均的な状況のために設計されているからです。安全性より効率性を優先します。データを集中化し、ハッカーや政府のハニーポットを作ります。文化的認識、アクセシビリティ、人間の監視が欠けています。

脆弱な人々にとって、これらはバグではありません。存続の脅威です。AIの失敗は不便ではありません—それは破局です。」

---

## Slide 4: The Inspiration - 500 Years of Wisdom

**Speaker Notes (English):**

"When we started this project, we did what most researchers do. We looked at the latest papers. RLHF. Constitutional AI. Alignment techniques. But nothing felt right. We were trying to make AI safe in isolation, then deploy it to vulnerable communities. It felt backwards.

Then Kotoku-sensei told us about her grandmother in Okinawa. Her grandmother is 96 years old. She has never been to a hospital for a major illness. She's mentally sharp, physically active, happy. And she's not alone—Okinawa has the highest concentration of centenarians in the world.

The secret? MOAI. 模合.

Her grandmother has belonged to the same MOAI for 73 years. Five people. Just five. They've been through everything together—births, deaths, celebrations, crises. They meet weekly. They pool money for emergencies. They support each other emotionally, financially, practically.

And here's what struck us: the 5-person limit isn't arbitrary. It's small enough to build deep trust. Small enough to know everyone intimately. Small enough that privacy is natural—there's no surveillance at scale, no data aggregation, no system to hack.

500 years of social technology. Proven. Effective. Documented by the Okinawa Centenarian Study as a key factor in longevity.

We asked ourselves: What if we didn't replace this system with AI? What if we augmented it? What if the technology served the human relationships, instead of replacing them?"

**発表者ノート（日本語）:**

「このプロジェクトを始めたとき、私たちはほとんどの研究者がすることをしました。最新の論文を調べました。RLHF。Constitutional AI。アライメント技術。でも、どれもしっくりきませんでした。私たちは孤立してAIを安全にしようとし、それから脆弱なコミュニティに展開しようとしていました。逆だと感じました。

それから神徳先生が沖縄のおばあさんのことを話してくれました。おばあさんは96歳です。大きな病気で病院に行ったことがありません。精神的にシャープで、身体的に活動的で、幸せです。そして彼女は一人ではありません—沖縄は世界で最も百寿者の濃度が高い場所です。

秘訣は？模合。

おばあさんは73年間同じ模合に所属しています。5人。たった5人。彼らは一緒にすべてを経験してきました—誕生、死、祝い、危機。毎週会います。緊急時のためにお金を出し合います。感情的に、経済的に、実践的にお互いをサポートします。

そして私たちを驚かせたのは：5人という制限は恣意的ではないということです。深い信頼を築くのに十分小さい。全員を親密に知るのに十分小さい。プライバシーが自然である十分小さい—大規模な監視、データ集約、ハッキングするシステムがありません。

500年の社会技術。実証済み。効果的。沖縄百寿者研究によって長寿の重要な要因として文書化されています。

私たちは自問しました：このシステムをAIで置き換えないとしたらどうだろう？それを強化したらどうだろう？技術が人間関係を置き換えるのではなく、人間関係に奉仕するとしたらどうだろう？」

---

## Slide 5: The Vision - Augmentation, Not Replacement

**Speaker Notes (English):**

"Let me paint you a picture of what this looks like.

Imagine Haruto's MOAI—Shinrai MOAI, which means 'Trust MOAI.' Five elderly people living in the same neighborhood. They still meet every Tuesday at the community center for tea. They still make decisions together. They still pool their emergency fund.

But now, each of them has a personal AI assistant. Not a generic chatbot—an AI that knows Haruto prefers formal Japanese, knows he takes his pills at 8 AM and 8 PM, knows he gets anxious when his daughter doesn't call.

There's also a group coordinator AI that helps schedule their Tuesday meetings at wheelchair-accessible venues, that notices when someone hasn't checked in, that handles the boring logistics so they can focus on being human together.

And there's an accessibility AI that adapts the interface for each person—large text for Haruto's aging eyes, voice control for Keiko who has arthritis, 'Easy Japanese' for members with cognitive changes.

And critically, there's an emergency response coordinator that can mobilize the entire group instantly when someone needs help.

But here's the key: the AI suggests. The humans decide. Always. The five members collectively govern how much automation they want, what the AI can and cannot do, when it should escalate to humans.

The traditional MOAI structure provides natural guardrails. The AI provides superhuman coordination. Together, they create something neither could achieve alone."

**発表者ノート（日本語）:**

「これがどのように見えるか、絵を描いてみましょう。

ハルトの模合を想像してください—信頼模合、「信頼」を意味します。同じ近所に住む5人の高齢者。彼らはまだ毎週火曜日にコミュニティセンターでお茶のために会います。まだ一緒に決定を下します。まだ緊急基金を出し合います。

しかし今、彼らそれぞれが個人AIアシスタントを持っています。一般的なチャットボットではありません—ハルトが丁寧な日本語を好むことを知っている、彼が午前8時と午後8時に薬を飲むことを知っている、娘が電話しないときに不安になることを知っているAIです。

また、火曜日の会議を車椅子アクセス可能な会場でスケジュールするのを助けるグループコーディネーターAI、誰かがチェックインしていないことに気づくAI、退屈な物流を処理して彼らが一緒に人間であることに集中できるようにするAIがあります。

そして、各人のためにインターフェースを適応させるアクセシビリティAIがあります—ハルトの老化した目のための大きなテキスト、関節炎のある恵子さんのための音声制御、認知変化のあるメンバーのための「やさしい日本語」。

そして重要なのは、誰かが助けを必要とするときにグループ全体を即座に動員できる緊急対応コーディネーターがあることです。

しかし、ここが鍵です：AIは提案します。人間が決定します。常に。5人のメンバーは、どれだけの自動化を望むか、AIが何をできて何をできないか、いつ人間にエスカレートすべきかを集団的に管理します。

伝統的な模合構造は自然なガードレールを提供します。AIは超人的な調整を提供します。一緒に、彼らはどちらも単独では達成できない何かを創造します。」

---

## Slide 6: Live Demo - See It Work

**Speaker Notes (English):**

"Let me show you what this actually looks like. This is the real dashboard for Tokyo Community Builders MOAI.

You see five members. An emergency fund of 50,000 yen—not managed by some corporation, but by the MOAI's own legal entity. Yes, each MOAI is legally incorporated. It can hold assets, sign contracts, protect its members' privacy while still interfacing with systems that require organizational identity.

Look at the navigation: Chat, Activities, Media, Finance, AI Assistant. Simple. Clean. Available in Japanese and English, with 'Easy Japanese' mode for those who need it.

This isn't a mockup. This is running on the AIngle DLT platform we've built. Every interaction is local-first—your data stays on your device, syncs peer-to-peer with your MOAI members only. No cloud. No central server to breach. No company that can be subpoenaed for your private conversations.

The interface adapts. If you're Daichi with cerebral palsy, you use voice control and simplified gestures. If you're Haruto with aging eyes, you get high contrast and larger text. If you're Yui with social anxiety, you can participate through text without ever showing your face.

This is what happens when you design for the most vulnerable first. Everyone benefits."

**発表者ノート（日本語）:**

「実際にこれがどのように見えるかお見せしましょう。これは東京コミュニティビルダーズ模合の実際のダッシュボードです。

5人のメンバーが見えます。50,000円の緊急基金—企業によって管理されているのではなく、模合自身の法人によって管理されています。そうです、各模合は法的に設立されています。資産を保有し、契約に署名し、組織アイデンティティを必要とするシステムとインターフェースしながらもメンバーのプライバシーを保護できます。

ナビゲーションを見てください：チャット、活動、メディア、会計、AIアシスタント。シンプル。クリーン。日本語と英語で利用可能で、必要な人のための「やさしい日本語」モードがあります。

これはモックアップではありません。これは私たちが構築したAIngle DLTプラットフォームで動作しています。すべてのインタラクションはローカルファースト—データはあなたのデバイスに留まり、あなたの模合メンバーとのみピアツーピアで同期します。クラウドなし。侵害される中央サーバーなし。あなたのプライベートな会話について召喚状を受け取ることができる会社なし。

インターフェースは適応します。脳性麻痺のダイチなら、音声制御と簡略化されたジェスチャーを使います。老化した目のハルトなら、高コントラストと大きなテキストを取得します。社交不安のあるユイなら、顔を見せずにテキストで参加できます。

これは、最も脆弱な人々のために最初に設計したときに起こることです。全員が利益を得ます。」

---

## Slide 7: Five Real MOAIs - Five Lives

**Speaker Notes (English):**

"We're not building one MOAI. We're building five, each serving a different vulnerable population. Because vulnerability isn't monolithic—it's diverse, intersectional, specific.

Shinrai MOAI—Trust MOAI—for elderly people like Haruto aging in place. Medical emergencies. Loneliness. Scam protection.

Mirai MOAI—Future MOAI—for people like Daichi with cerebral palsy. Accessibility isn't an afterthought here—it's the foundation. Voice control, simplified interfaces, event coordination that ensures wheelchair accessibility.

Kibou MOAI—Hope MOAI—for people like Yui who are hikikomori. Two years of social withdrawal. The AI knows to start with text-only, to never push, to move at Yui's pace.

Yuiitsu MOAI—Unique MOAI—for LGBTQ+ individuals like Sakura. Privacy isn't optional—it's survival. The legal entity can sign housing contracts without exposing Sakura's transgender status.

Jiyuu MOAI—Freedom MOAI—for undocumented immigrants like Sora. Local-first architecture means immigration status never leaves Sora's device. She can get community support without risking deportation.

Five groups. Five sets of needs. One principle: AI serves the humans, and the humans govern the AI."

**発表者ノート（日本語）:**

「私たちは一つの模合を構築しているのではありません。五つ構築しています。それぞれが異なる脆弱な人々にサービスを提供しています。なぜなら、脆弱性は一枚岩ではありません—多様で、交差的で、具体的だからです。

信頼模合—ハルトのような在宅で老化する高齢者のため。医療緊急事態。孤独。詐欺保護。

未来模合—脳性麻痺のダイチのような人々のため。アクセシビリティはここでは後付けではありません—基盤です。音声制御、簡略化されたインターフェース、車椅子アクセシビリティを保証するイベント調整。

希望模合—ユイのようなひきこもりの人々のため。2年間の社会的引きこもり。AIはテキストのみで始めること、決して押し付けないこと、ユイのペースで動くことを知っています。

唯一模合—サクラのようなLGBTQ+の個人のため。プライバシーは選択ではありません—生存です。法人はサクラのトランスジェンダーステータスを暴露せずに住宅契約に署名できます。

自由模合—ソラのような非正規滞在者のため。ローカルファーストアーキテクチャは、移民ステータスがソラのデバイスから決して出ないことを意味します。彼女は国外退去のリスクなしにコミュニティサポートを得ることができます。

5つのグループ。5つのニーズ。一つの原則：AIは人間に奉仕し、人間がAIを管理します。」

---

## Slide 8: User Journey - Yui's Transformation

**Speaker Notes (English):**

"Let me tell you Yui's story in detail, because it shows how different this approach is.

Month 0: Yui's mother is desperate. Her daughter hasn't left her room in two years. Every attempt to 'get her out there' has failed. Through online mental health resources, she finds Kibou MOAI.

Month 1: First contact. Not a phone call—that would be too much. A text message. The AI knows to keep it simple: 'Hi, I'm here when you're ready. No pressure.' Yui doesn't respond. That's okay.

Month 2: The AI shares a photo the other members posted—a cat café they visited. No obligation to comment. Yui sees it. She likes cats.

Month 4: Yui sends her first message. One word: 'Cute.' The group responds with warmth, not overwhelming enthusiasm. The AI calibrates—it knows not to escalate too fast.

Month 6: Online voice chat. Camera off. Yui just listens. Hears other people with anxiety sharing their struggles. For the first time in two years, she doesn't feel alone.

Month 8: The first in-person meeting. At a quiet café, one hour maximum, another anxious member present, exit strategy prepared. Yui stays 45 minutes. It's exhausting. It's terrifying. It's progress.

Month 12: Yui volunteers to design event posters remotely. She has graphic design skills nobody knew about. She feels useful. Valued. Connected.

The AI made this possible by understanding that healing isn't linear, that support means meeting people where they are, that technology should adapt to humans, not the other way around."

**発表者ノート（日本語）:**

「ユイの物語を詳しくお話しさせてください。このアプローチがどれほど違うかを示しているからです。

0ヶ月目：ユイの母親は必死です。娘は2年間部屋から出ていません。「外に出る」試みはすべて失敗しました。オンラインのメンタルヘルスリソースを通じて、彼女は希望模合を見つけます。

1ヶ月目：最初の接触。電話ではありません—それは多すぎます。テキストメッセージ。AIはシンプルに保つことを知っています：「こんにちは、準備ができたらここにいます。プレッシャーはありません。」ユイは返信しません。それでいいです。

2ヶ月目：AIは他のメンバーが投稿した写真を共有します—彼らが訪れた猫カフェ。コメントする義務はありません。ユイはそれを見ます。彼女は猫が好きです。

4ヶ月目：ユイが最初のメッセージを送ります。一言：「かわいい。」グループは圧倒的な熱意ではなく、温かさで応答します。AIは較正します—速すぎるエスカレーションはしないことを知っています。

6ヶ月目：オンライン音声チャット。カメラオフ。ユイはただ聞きます。不安を抱える他の人々が苦闘を共有するのを聞きます。2年ぶりに、彼女は一人ではないと感じます。

8ヶ月目：最初の対面ミーティング。静かなカフェで、最大1時間、別の不安なメンバーが同席し、退出戦略が準備されています。ユイは45分滞在します。疲れます。恐ろしいです。進歩です。

12ヶ月目：ユイはリモートでイベントポスターをデザインすることを志願します。誰も知らなかったグラフィックデザインのスキルを持っています。彼女は役に立つと感じます。価値があると。つながっていると。

AIはこれを可能にしました。癒しは直線的ではないこと、サポートは人々がいる場所で会うことを意味すること、技術は人間に適応すべきであり、その逆ではないことを理解することによって。」

---

## Slide 9: Storyboard - The Night Haruto Survived

**Speaker Notes (English):**

"Now let me take you back to that night. Panel by panel.

Panel 1: 11:47 PM. Haruto at his kitchen table. A termination letter from his part-time job—the stress has been building for weeks. Chest pain. Fear on his face.

Panel 2: His phone is in his hand. He taps the emergency button. The interface is simple—no complex menu, no confusion. Medical Emergency. One tap.

Panel 3: Behind the scenes, the magic happens. But it's not magic—it's architecture. The AI pulls his medical records from encrypted local storage. It notifies the four Shinrai MOAI members with priority alerts. It contacts emergency services with his location and preliminary medical information.

Panel 4: Keiko sees the alert on her phone. She's in her pajamas, but she runs. The other three members join a video call—they can see Haruto, provide emotional support, coordinate next steps. They're not medical professionals, but they're family.

Panel 5: Five minutes later. The paramedics arrive. Keiko hands them the tablet with Haruto's complete medical history—conditions, medications, allergies, recent stress factors. No fumbling for information. No dangerous gaps.

Panel 6: Two days later. Haruto is recovering in the hospital. The MOAI has coordinated visits—someone every day. Meals delivered to his apartment so he has something when he comes home. The emergency fund covered the ambulance. The legal entity is handling the insurance paperwork.

This is what 0.16 millisecond latency means in real life. This is what privacy-preserving architecture enables. This is what happens when AI augments human community instead of replacing it."

**発表者ノート（日本語）:**

「では、あの夜に戻りましょう。パネルごとに。

パネル1：午後11時47分。キッチンテーブルのハルト。パートタイムの仕事からの解雇通知—ストレスが数週間蓄積されています。胸の痛み。彼の顔に恐怖。

パネル2：彼の電話は彼の手にあります。彼は緊急ボタンをタップします。インターフェースはシンプルです—複雑なメニューなし、混乱なし。医療緊急事態。ワンタップ。

パネル3：舞台裏で、魔法が起こります。しかしそれは魔法ではありません—アーキテクチャです。AIは暗号化されたローカルストレージから彼の医療記録を引き出します。優先度の高いアラートで信頼模合の4人のメンバーに通知します。彼の位置と予備的な医療情報で緊急サービスに連絡します。

パネル4：恵子さんは彼女の電話でアラートを見ます。彼女はパジャマ姿ですが、走ります。他の3人のメンバーはビデオ通話に参加します—彼らはハルトを見ることができ、感情的なサポートを提供し、次のステップを調整します。彼らは医療専門家ではありませんが、家族です。

パネル5：5分後。救急隊員が到着します。恵子さんは彼らにハルトの完全な病歴を含むタブレットを渡します—状態、薬、アレルギー、最近のストレス要因。情報を探し回ることなし。危険なギャップなし。

パネル6：2日後。ハルトは病院で回復しています。模合は訪問を調整しました—毎日誰か。家に帰ってきたときに何かあるように、彼のアパートに配達される食事。緊急基金が救急車をカバーしました。法人が保険の書類を処理しています。

これが実生活での0.16ミリ秒のレイテンシが意味することです。これがプライバシー保護アーキテクチャが可能にすることです。これがAIが人間のコミュニティを置き換えるのではなく強化したときに起こることです。」

---

## Slide 10: The Technology - How It Actually Works

**Speaker Notes (English):**

"I know what you're thinking. This sounds too good to be true. Where's the catch?

There's no catch. But there is sophisticated technology making it possible.

The platform is called AIngle DLT. We built it originally for the EU H2020 FASTER project—first responder emergency communication. When seconds matter. When lives are on the line. When privacy cannot be compromised because you're dealing with victims, witnesses, sensitive situations.

Everything is local-first. Your data lives on your device. When you sync with your MOAI members, it's peer-to-peer, encrypted. There's no cloud server in California or Tokyo that has a copy of your conversations, your medical records, your location history.

The semantic knowledge layer—RDF and OWL ontologies—is what enables cultural awareness. The AI doesn't just translate words. It understands that Haruto prefers formal speech because of his generation and background. It knows that 'Easy Japanese' isn't just simplified vocabulary—it's a whole accessibility framework developed for non-native speakers and people with cognitive disabilities.

We've benchmarked this rigorously. 0.16 milliseconds average latency for semantic queries. Over 7,000 transactions per second peak throughput. Over 2 million operations tested. 100% reliability.

And crucially—offline first. When the internet goes down in a disaster, Digital MOAI keeps working. Local storage, local computation, eventual consistency when connectivity returns. Because vulnerable populations are often in areas with poor connectivity, and they're often the ones who need help most during disasters."

**発表者ノート（日本語）:**

「皆さんが考えていることは分かります。これは本当であるにはあまりにも良すぎる。裏は？

裏はありません。しかし、それを可能にする洗練された技術があります。

プラットフォームはAIngle DLTと呼ばれています。私たちは元々EU H2020 FASTERプロジェクト—初動対応者の緊急通信のためにこれを構築しました。秒が重要なとき。命が危機にさらされているとき。被害者、目撃者、デリケートな状況を扱っているためプライバシーが妥協できないとき。

すべてがローカルファーストです。データはあなたのデバイスに保存されます。模合メンバーと同期するとき、ピアツーピア、暗号化されています。カリフォルニアや東京にあなたの会話、医療記録、位置履歴のコピーを持っているクラウドサーバーはありません。

セマンティック知識レイヤー—RDFとOWLオントロジー—が文化的認識を可能にしているものです。AIは単に言葉を翻訳するのではありません。ハルトが世代と背景のために丁寧な話し方を好むことを理解しています。「やさしい日本語」が単に簡略化された語彙ではないことを知っています—それは非母語話者や認知障害を持つ人々のために開発された全体的なアクセシビリティフレームワークです。

私たちはこれを厳密にベンチマークしました。セマンティッククエリの平均レイテンシ0.16ミリ秒。ピークスループット毎秒7,000トランザクション以上。200万以上の操作がテストされました。信頼性100%。

そして重要なこと—オフラインファースト。災害でインターネットがダウンしたとき、デジタル模合は動作し続けます。ローカルストレージ、ローカル計算、接続が戻ったときの最終的一貫性。脆弱な人々はしばしば接続性の悪い地域にいて、災害時に最も助けを必要とする人々であることが多いからです。」

---

## Slide 11: Four Principles - Our North Star

**Speaker Notes (English):**

"Building this taught us that principles matter more than features. We could add a thousand capabilities, but if we violate these four principles, we fail the people who need us most.

Principle 1: Human Primacy. Our early prototypes gave the AI more autonomy. Users hated it. They felt watched, controlled, infantilized. We learned: AI suggests, humans decide. Always. No exceptions.

Principle 2: Accessibility First. Not accessibility as a checkbox. Accessibility as the foundation. When we designed for Daichi's needs—voice control, simplified gestures—we discovered older users preferred it too. Universal design benefits everyone.

Principle 3: Privacy Sovereignty. This isn't about compliance with GDPR. This is existential. Sora cannot use our system if her immigration status could be exposed. Sakura cannot trust us if her medical records could leak. Privacy isn't a feature—it's a requirement for access.

Principle 4: Cultural Context-Awareness. We tried machine translation at first. It failed spectacularly. Translating words isn't enough. You need to understand that Haruto's communication style reflects his generation, his region, his values. That 'Easy Japanese' serves multiple populations—immigrants, people with cognitive disabilities, older adults learning new technology.

These aren't aspirational goals. They're hard requirements. Violate them and we lose the trust of the people we're trying to serve."

**発表者ノート（日本語）:**

「これを構築することで、原則が機能よりも重要であることを学びました。私たちは千の機能を追加できますが、これらの4つの原則に違反すると、私たちを最も必要とする人々を失望させます。

原則1：人間の優位性。初期のプロトタイプはAIにより多くの自律性を与えました。ユーザーはそれを嫌いました。監視されている、制御されている、幼稚に扱われていると感じました。私たちは学びました：AIは提案し、人間が決定します。常に。例外なし。

原則2：アクセシビリティファースト。チェックボックスとしてのアクセシビリティではありません。基盤としてのアクセシビリティ。ダイチのニーズのために設計したとき—音声制御、簡略化されたジェスチャー—高齢ユーザーもそれを好むことを発見しました。ユニバーサルデザインは全員に利益をもたらします。

原則3：プライバシー主権。これはGDPRへの準拠についてではありません。これは存続です。ソラは、彼女の移民ステータスが暴露される可能性がある場合、私たちのシステムを使用できません。サクラは、彼女の医療記録が漏洩する可能性がある場合、私たちを信頼できません。プライバシーは機能ではありません—アクセスのための要件です。

原則4：文化的文脈認識。最初に機械翻訳を試しました。それは見事に失敗しました。言葉を翻訳するだけでは不十分です。ハルトのコミュニケーションスタイルが彼の世代、地域、価値観を反映していることを理解する必要があります。「やさしい日本語」が複数の人々—移民、認知障害を持つ人々、新しい技術を学ぶ高齢者—にサービスを提供することを。

これらは願望的な目標ではありません。厳しい要件です。それらに違反すると、私たちが奉仕しようとしている人々の信頼を失います。」

---

## Slide 12: Trust Calibration - Respecting Agency

**Speaker Notes (English):**

"Let me tell you about what happened when we got this wrong.

In an early version, we made the AI 'helpful.' If someone missed their medication reminder twice, the AI would automatically notify their MOAI members. We thought we were being proactive.

Users revolted. Rightfully so. We had violated their agency. Made them feel like children being tattled on.

We learned: trust isn't binary. It's calibrated. It evolves.

Level 1—Suggestion Only—is the default. The AI says: 'I noticed you haven't taken your evening medication. Would you like a reminder?' And it waits. It shows you its reasoning. It gives you complete control.

Level 2—Automatic with Notification—comes after you've built trust. The AI takes routine actions but immediately tells you what it did, with a 24-hour undo window. It's like having an assistant who acts but keeps you informed.

Level 3—Automatic with Escalation—is for experienced users with well-calibrated trust. The AI handles routine tasks independently but immediately escalates anything unusual. It knows the difference between 'Haruto's regular Tuesday meeting' and 'Haruto hasn't responded to check-ins for three days.'

And critically: all five MOAI members must agree on automation policies. Haruto can't opt Keiko into Level 3 automation. This is collective governance.

Trust is earned. Slowly. With transparency. With user control. Always."

**発表者ノート（日本語）:**

「これを間違えたときに何が起こったかお話しさせてください。

初期バージョンで、私たちはAIを「親切」にしました。誰かが薬のリマインダーを2回逃した場合、AIは自動的に模合メンバーに通知します。私たちは積極的だと思いました。

ユーザーは反乱を起こしました。当然です。私たちは彼らの主体性を侵害しました。告げ口される子供のように感じさせました。

私たちは学びました：信頼は二値ではありません。較正されます。進化します。

レベル1—提案のみ—がデフォルトです。AIは言います：「夕方の薬を服用していないことに気づきました。リマインダーが必要ですか？」そして待ちます。推論を見せます。完全なコントロールを与えます。

レベル2—通知付き自動—は信頼を築いた後に来ます。AIは定型アクションを実行しますが、24時間の取り消しウィンドウで何をしたかをすぐに伝えます。行動するが情報を提供するアシスタントを持っているようなものです。

レベル3—エスカレーション付き自動—は、よく較正された信頼を持つ経験豊富なユーザーのためです。AIは定型タスクを独立して処理しますが、異常なものはすぐにエスカレートします。「ハルトの定期的な火曜日の会議」と「ハルトが3日間チェックインに応答していない」の違いを知っています。

そして重要なこと：すべての5人の模合メンバーが自動化ポリシーに同意する必要があります。ハルトは恵子さんをレベル3自動化に参加させることはできません。これは集団的ガバナンスです。

信頼は獲得されます。ゆっくりと。透明性を持って。ユーザーコントロールを持って。常に。」

---

## Slide 13: Accessibility - Designed Together

**Speaker Notes (English):**

"I want to introduce you to Daichi. He's 28, cerebral palsy, uses a wheelchair, has limited fine motor control in his hands.

In our first meeting with Daichi, we showed him our interface. Buttons. Menus. Standard design.

He looked at it and said: 'I can't use this.'

We could have said: 'Okay, we'll add accessibility features.' But that's the wrong approach. That's retrofitting. That's treating accessibility as a compliance checkbox.

Instead, we said: 'Teach us how to build this right.'

Daichi became our lead accessibility consultant. Not because we felt sorry for him. Because he's the expert. He knows what works. He knows what fails.

Voice control became the primary input method. Not mouse-first with voice as backup. Voice-first.

Gesture simplification. Not 'make smaller hit targets bigger.' Eliminate the need for precision altogether.

High-contrast modes. Haptic feedback. Screen reader optimization. Progressive disclosure—don't overwhelm with options, reveal complexity gradually.

And then something beautiful happened. Older users started preferring Daichi's interface. People with temporary disabilities—broken arm, eye surgery—found it easier. Non-native speakers found the simplified interaction more approachable.

Universal design isn't charity. It's good design. When you design for the edges, you improve the center."

**発表者ノート（日本語）:**

「ダイチを紹介したいと思います。彼は28歳、脳性麻痺、車椅子を使用し、手の細かい運動制御が限られています。

ダイチとの最初のミーティングで、私たちはインターフェースを見せました。ボタン。メニュー。標準的なデザイン。

彼はそれを見て言いました：「これは使えません。」

私たちは言うこともできました：「わかりました、アクセシビリティ機能を追加します。」しかし、それは間違ったアプローチです。それは後付けです。それはアクセシビリティをコンプライアンスのチェックボックスとして扱っています。

代わりに、私たちは言いました：「これを正しく構築する方法を教えてください。」

ダイチは私たちの主任アクセシビリティコンサルタントになりました。私たちが彼を気の毒に思ったからではありません。彼が専門家だからです。彼は何が機能するかを知っています。何が失敗するかを知っています。

音声制御が主要な入力方法になりました。バックアップとして音声を持つマウスファーストではありません。音声ファースト。

ジェスチャーの簡略化。「より小さなヒットターゲットをより大きくする」ではありません。精度の必要性を完全に排除します。

高コントラストモード。触覚フィードバック。スクリーンリーダーの最適化。段階的開示—オプションで圧倒しない、複雑さを徐々に明らかにする。

そして美しいことが起こりました。高齢ユーザーがダイチのインターフェースを好むようになりました。一時的な障害を持つ人々—骨折した腕、目の手術—はそれをより簡単だと感じました。非母語話者は簡略化されたインタラクションをよりアプローチしやすいと感じました。

ユニバーサルデザインは慈善ではありません。良いデザインです。エッジのために設計するとき、センターを改善します。」

---

## Slide 14: Privacy & Legal Innovation - Why It Matters

**Speaker Notes (English):**

"Remember Sora? Let me tell you what happened to her friend Maria.

Maria is also undocumented. She needed emergency housing assistance. She went to a nonprofit that uses a 'helpful' AI system to process requests. The system required her to upload identification, employment records, housing history.

The nonprofit's database was breached six months later. Maria's information was sold to ICE. She was deported. Her children, born in Japan, are now in foster care.

This isn't theoretical. Data breaches happen. Governments subpoena databases. Well-meaning systems become weapons against the vulnerable.

Digital MOAI takes a radically different approach. Each MOAI is a legally incorporated entity. It has its own legal personhood. When Jiyuu MOAI signs a lease for emergency housing, the landlord sees the organization, not Sora's individual identity.

All personal data stays on user devices. Peer-to-peer synchronization within the MOAI only. No central server. No honeypot for hackers. No database for governments to subpoena.

Location sharing? Opt-in, time-limited, MOAI-members only. Medical records? Encrypted, user-controlled, shared only when the user explicitly consents. Financial transactions? Through the legal entity, not personal bank accounts.

And offline operation—when internet goes down, the system keeps working. Because vulnerable populations are often in disasters, in rural areas, in situations where connectivity is compromised.

This isn't paranoia. This is reality for millions of people. Privacy isn't a feature. It's survival."

**発表者ノート（日本語）:**

「ソラを覚えていますか？彼女の友人マリアに何が起こったかお話しさせてください。

マリアも非正規滞在者です。彼女は緊急住宅援助を必要としていました。彼女は要求を処理するために「親切な」AIシステムを使用する非営利団体に行きました。システムは彼女に身分証明、雇用記録、住宅履歴をアップロードすることを要求しました。

非営利団体のデータベースは6ヶ月後に侵害されました。マリアの情報は入国管理局に売られました。彼女は国外退去させられました。日本で生まれた彼女の子供たちは現在、里親養育にいます。

これは理論ではありません。データ漏洩は起こります。政府はデータベースを召喚します。善意のシステムは脆弱な人々に対する武器になります。

デジタル模合は根本的に異なるアプローチを取ります。各模合は法的に設立された組織です。それは独自の法人格を持っています。自由模合が緊急住宅のためにリースに署名するとき、家主は組織を見ます、ソラの個人的アイデンティティではありません。

すべての個人データはユーザーデバイスに留まります。模合内のみのピアツーピア同期。中央サーバーなし。ハッカーのためのハニーポットなし。政府が召喚するデータベースなし。

位置共有？オプトイン、時間制限、模合メンバーのみ。医療記録？暗号化、ユーザー制御、ユーザーが明示的に同意したときのみ共有。金融取引？法人を通じて、個人銀行口座ではありません。

そしてオフライン操作—インターネットがダウンしたとき、システムは動作し続けます。脆弱な人々はしばしば災害、農村地域、接続性が損なわれている状況にいるからです。

これは被害妄想ではありません。これは何百万もの人々にとっての現実です。プライバシーは機能ではありません。生存です。」

---

## Slide 15: Implementation Status - What's Real

**Speaker Notes (English):**

"I need to be honest with you about where we are.

The AIngle DLT platform is 85% complete and production-ready. It compiles. The tests pass. We've benchmarked it with over 2 million operations. The distributed architecture works. The semantic layer works. The encryption works.

The Digital MOAI application is 40% complete. The dashboard you saw is real. The onboarding flow exists. The bilingual interface works. Personal AI assistant integration is in progress.

What's not done? The offline operation capabilities are planned but not implemented. Advanced accessibility features like sign language support are designed but not built. Voice and avatar interaction is on the roadmap.

And most importantly—field studies with actual MOAI groups are planned under Dr. Kotoku's JSPS KAKENHI grant, but haven't started yet.

I'm telling you this because I respect you. Because this community values honesty. Because overselling our capabilities would be a betrayal of the vulnerable populations we're trying to serve.

This presentation focuses on what we've built, what we've designed, and what we've learned. The gaps are opportunities for collaboration, not failures.

We're not selling you a product. We're inviting you into a research journey."

**発表者ノート（日本語）:**

「私たちがどこにいるかについて正直でなければなりません。

AIngle DLTプラットフォームは85%完成し、本番準備ができています。コンパイルします。テストは合格します。200万以上の操作でベンチマークしました。分散アーキテクチャは機能します。セマンティックレイヤーは機能します。暗号化は機能します。

デジタル模合アプリケーションは40%完成しています。あなたが見たダッシュボードは本物です。オンボーディングフローは存在します。バイリンガルインターフェースは機能します。個人AIアシスタント統合は進行中です。

何が完成していないか？オフライン操作機能は計画されていますが、実装されていません。手話サポートのような高度なアクセシビリティ機能は設計されていますが、構築されていません。音声とアバターインタラクションはロードマップにあります。

そして最も重要なこと—実際の模合グループでのフィールド研究は神徳教授のJSPS科研費助成の下で計画されていますが、まだ始まっていません。

これをお話しするのは、あなたを尊重しているからです。このコミュニティが正直さを重視しているからです。私たちの能力を過大に売り込むことは、私たちが奉仕しようとしている脆弱な人々への裏切りになるからです。

本発表は、私たちが構築したもの、設計したもの、学んだことに焦点を当てています。ギャップは失敗ではなく、協力の機会です。

私たちは製品を売っているのではありません。研究の旅にあなたを招待しています。」

---

## Slide 16: Key Contributions - What We Offer MASST

**Speaker Notes (English):**

"So what does Digital MOAI contribute to the MASST community? Seven things:

First, an alternative safety paradigm. Not 'train AI until it's safe,' but 'embed AI in social structures that have kept people safe for 500 years.' Safety by social structure, not safety by algorithm alone.

Second, an architectural pattern. How do you augment traditional wisdom with modern technology? How do you preserve human agency while adding AI capabilities? This is replicable beyond MOAI—think about other community support structures worldwide.

Third, an accessibility framework. Not retrofitted accommodation, but universal design from day one. Proof that designing for the edges improves the center.

Fourth, a privacy-preserving platform with verified real-time performance. 0.16 milliseconds doesn't just sound good—it means the difference between life and death in emergencies.

Fifth, legal innovation. The idea that community groups can have legal personhood, can interface with systems that require organizational identity while protecting individual privacy.

Sixth, an empirical framework. Five vulnerable populations. Five personas with names and stories. Five sets of requirements. This is applied research with real stakes.

Seventh, cultural adaptation. How do you make AI that works across cultures without cultural imperialism? Semantic ontologies that understand context, not just translate words.

This is what we bring to the table. Not just another AI paper. A new paradigm."

**発表者ノート（日本語）:**

「では、デジタル模合はMASTコミュニティに何を貢献するのでしょうか？7つのことです：

第一に、代替安全性パラダイム。「安全になるまでAIを訓練する」ではなく、「500年間人々を安全に保ってきた社会構造にAIを埋め込む」。アルゴリズムだけによる安全性ではなく、社会構造による安全性。

第二に、アーキテクチャパターン。伝統的な知恵を現代技術で強化する方法は？AI機能を追加しながら人間の主体性を保つ方法は？これは模合を超えて再現可能です—世界中の他のコミュニティサポート構造を考えてください。

第三に、アクセシビリティフレームワーク。後付けの配慮ではなく、初日からのユニバーサルデザイン。エッジのために設計することがセンターを改善する証明。

第四に、検証済みリアルタイムパフォーマンスを持つプライバシー保護プラットフォーム。0.16ミリ秒は良く聞こえるだけでなく、緊急時に生と死の違いを意味します。

第五に、法的イノベーション。コミュニティグループが法人格を持つことができ、個人のプライバシーを保護しながら組織アイデンティティを必要とするシステムとインターフェースできるという考え。

第六に、実証フレームワーク。5つの脆弱な人々。名前と物語を持つ5つのペルソナ。5つの要件セット。これは本当の賭け金を持つ応用研究です。

第七に、文化適応。文化帝国主義なしに文化を超えて機能するAIを作る方法は？単に言葉を翻訳するのではなく、文脈を理解するセマンティックオントロジー。

これが私たちがテーブルにもたらすものです。単なる別のAI論文ではありません。新しいパラダイムです。」

---

## Slide 17: MASST Alignment - We're On the Same Path

**Speaker Notes (English):**

"When we read the MASST call for papers, we realized: we're trying to solve the same problems.

Safety by design? Check. We don't bolt safety onto AI afterwards. We embed AI into structures that have safety built in.

Human-agent teamwork? Check. But we flip it. Not 'how do humans work with AI agents,' but 'how do AI agents support human teams that already work.'

Context-aware guardrails? Check. Semantic ontologies that understand culture, accessibility needs, individual preferences.

Mutual observability? Check. Every AI decision has transparent provenance. Every action can be audited. Every member can see what the AI is doing and why.

Calibrated trust? Check. Three automation levels. User-configured. Group-governed. Evolving with experience.

Privacy and security? Check. Local-first architecture. No central point of failure. Quantum-resistant identity planned.

But here's where we push further: we focus specifically on vulnerable populations. Because if AI safety works for Haruto, Sora, Yui, Daichi, and Sakura—it will work for everyone.

The edge cases aren't edge cases. They're the people who need us most. And they're the best test of whether we've actually solved multi-agent safety."

**発表者ノート（日本語）:**

「MASST論文募集を読んだとき、私たちは気づきました：私たちは同じ問題を解決しようとしています。

デザインによる安全性？チェック。後からAIに安全性をボルト締めしません。安全性が組み込まれた構造にAIを埋め込みます。

人間エージェントチームワーク？チェック。しかし私たちはそれを反転させます。「人間はどのようにAIエージェントと協力するか」ではなく、「AIエージェントはすでに機能している人間チームをどのようにサポートするか」。

文脈認識ガードレール？チェック。文化、アクセシビリティニーズ、個々の好みを理解するセマンティックオントロジー。

相互観察可能性？チェック。すべてのAI決定には透明な来歴があります。すべてのアクションを監査できます。すべてのメンバーはAIが何をしているか、なぜかを見ることができます。

較正された信頼？チェック。3つの自動化レベル。ユーザー設定。グループ管理。経験とともに進化。

プライバシーとセキュリティ？チェック。ローカルファーストアーキテクチャ。中央の障害点なし。量子耐性アイデンティティ計画済み。

しかし、ここで私たちはさらに進みます：私たちは特に脆弱な人々に焦点を当てます。なぜなら、AI安全性がハルト、ソラ、ユイ、ダイチ、サクラのために機能すれば—それは全員のために機能するからです。

エッジケースはエッジケースではありません。彼らは私たちを最も必要としている人々です。そして彼らは、私たちが実際にマルチエージェントの安全性を解決したかどうかの最良のテストです。」

---

## Slide 18: The Paradigm Shift - A Different Question

**Speaker Notes (English):**

"Most AI safety research asks: 'How do we make AI safe?'

We ask a different question: 'How do we make humans safe WITH AI?'

The traditional approach trains AI in isolation, tries to anticipate every edge case, then deploys and hopes for the best. It's an impossible task. The world is too complex. Contexts are too diverse. Edge cases are infinite.

Our approach: don't make AI safe in isolation. Embed it in social structures that have already solved the safety problem.

Traditional MOAI has kept people safe for 500 years. Not through algorithms. Through relationships. Through accountability. Through trust built over time. Through the constraint of small scale—you can't surveil 3 billion people with a 5-person group.

AI adds coordination. Real-time communication. Accessibility features. Emergency response. Semantic reasoning. Offline capabilities.

But the safety comes from the social structure. The AI serves that structure. It doesn't replace it.

Think about it: Haruto's life was saved not because the AI was smart, but because Keiko cared enough to run to his apartment in her pajamas. The AI just made that caring more effective.

This is the paradigm shift. Not training AI to understand vulnerability. Embedding AI in communities that already do."

**発表者ノート（日本語）:**

「ほとんどのAI安全性研究は尋ねます：『どのようにAIを安全にするか？』

私たちは異なる質問をします：『どのようにAIと共に人間を安全にするか？』

従来のアプローチは孤立してAIを訓練し、すべてのエッジケースを予測しようとし、それから展開して最善を期待します。それは不可能なタスクです。世界はあまりにも複雑です。文脈はあまりにも多様です。エッジケースは無限です。

私たちのアプローチ：孤立してAIを安全にしようとしません。すでに安全性問題を解決した社会構造にそれを埋め込みます。

伝統的な模合は500年間人々を安全に保ってきました。アルゴリズムを通じてではありません。関係を通じて。説明責任を通じて。時間をかけて構築された信頼を通じて。小規模の制約を通じて—5人グループで30億人を監視することはできません。

AIは調整を追加します。リアルタイム通信。アクセシビリティ機能。緊急対応。セマンティック推論。オフライン機能。

しかし、安全性は社会構造から来ます。AIはその構造に奉仕します。それを置き換えません。

考えてみてください：ハルトの命が救われたのは、AIが賢かったからではなく、恵子さんがパジャマ姿で彼のアパートに走るほど気にかけていたからです。AIはその思いやりをより効果的にしただけです。

これがパラダイムシフトです。AIに脆弱性を理解するよう訓練するのではありません。すでに理解しているコミュニティにAIを埋め込むことです。」

---

## Slide 19: Real-World Impact - Lives Changed

**Speaker Notes (English):**

"Let me show you what this looks like in practice. Five scenarios. Before and after.

Haruto's heart attack. Without Digital MOAI: alone, confused, delayed calling help, 30% higher mortality rate. With Digital MOAI: instant notification, Keiko there in 5 minutes, medical records ready, optimal care timeline. He survives.

Sora's housing crisis. Without: evicted, immigration status exposed, facing deportation, homeless. With: Jiyuu MOAI's legal entity signs the lease, her status remains private, stable housing secured. She stays.

Yui's isolation. Without: 2+ years of withdrawal, worsening mental health, family desperation. With: digital-first gentle engagement, 8 months of gradual trust-building, successful community re-integration. She reconnects.

Daichi's accessibility barriers. Without: can't attend community events, wheelchair inaccessible venues, no voice input options. With: AI coordinates accessible locations, voice-first interface, full participation. He belongs.

Sakura's safety crisis. Without: transphobic violence, exposed medical records, housing discrimination. With: emergency response from Yuiitsu MOAI, privacy-preserving legal entity, safe housing through group. She's protected.

These aren't hypotheticals. These are the user journeys we've mapped. The scenarios we've designed for. The people we're building this for.

Five lives. Five transformations. Five proofs that AI can serve humanity's most vulnerable when designed with them, not for them."

**発表者ノート（日本語）:**

「実際にこれがどのように見えるかお見せしましょう。5つのシナリオ。前と後。

ハルトの心臓発作。デジタル模合なし：一人、混乱、助けを求めるのが遅れる、死亡率30%高い。デジタル模合あり：即座の通知、5分で恵子さんがそこに、医療記録準備完了、最適なケアタイムライン。彼は生き延びます。

ソラの住宅危機。なし：追い出され、移民ステータスが暴露され、国外退去に直面し、ホームレス。あり：自由模合の法人がリースに署名、彼女のステータスはプライベートのまま、安定した住宅を確保。彼女は留まります。

ユイの孤立。なし：2年以上の引きこもり、悪化するメンタルヘルス、家族の絶望。あり：デジタルファーストの優しい関与、8ヶ月の段階的信頼構築、成功したコミュニティ再統合。彼女は再接続します。

ダイチのアクセシビリティ障壁。なし：コミュニティイベントに参加できない、車椅子アクセス不可能な会場、音声入力オプションなし。あり：AIがアクセス可能な場所を調整、音声ファーストインターフェース、完全な参加。彼は所属します。

サクラの安全危機。なし：トランスフォビックな暴力、暴露された医療記録、住宅差別。あり：唯一模合からの緊急対応、プライバシー保護法人、グループを通じた安全な住宅。彼女は保護されます。

これらは仮説ではありません。これらは私たちがマッピングしたユーザージャーニーです。私たちが設計したシナリオです。私たちがこれを構築している人々です。

5つの命。5つの変容。5つの証明、AIは彼らのためではなく、彼らと共に設計されたときに人類の最も脆弱な人々に奉仕できるという。」

---

## Slide 20: Lessons Learned - What Building This Taught Us

**Speaker Notes (English):**

"Building Digital MOAI taught us seven hard lessons. I want to share them because your projects will face the same challenges.

Lesson 1: Human primacy is non-negotiable. We tried giving AI more autonomy. Users felt controlled, infantilized, watched. We learned to pull back. Always.

Lesson 2: Accessibility benefits everyone. We designed voice control for Daichi. Then older users told us they preferred it. Then people with temporary disabilities loved it. Universal design isn't charity—it's good design.

Lesson 3: Privacy enables participation. Without local-first architecture, Sora and Sakura wouldn't join. For vulnerable populations, privacy isn't a feature—it's the price of admission.

Lesson 4: Legal entity is critical. We could have built the most perfect technical platform. But without legal personhood for MOAIs, Sora can't rent housing. Sakura can't sign insurance contracts. Technical excellence isn't enough.

Lesson 5: Cultural context can't be retrofitted. Machine translation failed spectacularly. We needed semantic ontologies that understand not just words, but meaning, context, cultural nuance. Build it in from day one.

Lesson 6: Five-person limit is a feature, not a bug. People kept asking: 'Can you make it scale to 50 people? 500?' No. Small scale creates trust. Preserves privacy. Enables accountability. Proliferate MOAIs, don't bloat them.

Lesson 7: Offline-first is essential. Internet connectivity is a privilege. Vulnerable populations are often in the places and situations where connectivity fails. If your system requires the internet, you're excluding the people who need you most.

These lessons came from listening to Haruto, Sora, Yui, Daichi, and Sakura. They're the experts. We're just the implementers."

**発表者ノート（日本語）:**

「デジタル模合を構築することは、7つの厳しい教訓を教えてくれました。あなたのプロジェクトも同じ課題に直面するので、それらを共有したいと思います。

教訓1：人間の優位性は譲れません。私たちはAIにより多くの自律性を与えようとしました。ユーザーは制御され、幼稚に扱われ、監視されていると感じました。私たちは引き下がることを学びました。常に。

教訓2：アクセシビリティは全員に利益をもたらします。私たちはダイチのために音声制御を設計しました。それから高齢ユーザーがそれを好むと言いました。それから一時的な障害を持つ人々がそれを愛しました。ユニバーサルデザインは慈善ではありません—良いデザインです。

教訓3：プライバシーが参加を可能にします。ローカルファーストアーキテクチャなしでは、ソラとサクラは参加しません。脆弱な人々にとって、プライバシーは機能ではありません—参加の価格です。

教訓4：法人は重要です。私たちは最も完璧な技術プラットフォームを構築できたかもしれません。しかし模合の法人格なしでは、ソラは住宅を借りることができません。サクラは保険契約に署名できません。技術的卓越性だけでは不十分です。

教訓5：文化的文脈は後付けできません。機械翻訳は見事に失敗しました。私たちは単に言葉だけでなく、意味、文脈、文化的ニュアンスを理解するセマンティックオントロジーが必要でした。初日から構築してください。

教訓6：5人制限は機能であり、バグではありません。人々は尋ね続けました：「50人にスケールできますか？500人？」いいえ。小規模が信頼を生み出します。プライバシーを保ちます。説明責任を可能にします。模合を増殖させ、肥大化させないでください。

教訓7：オフラインファーストは必須です。インターネット接続は特権です。脆弱な人々はしばしば接続が失敗する場所や状況にいます。あなたのシステムがインターネットを必要とする場合、あなたを最も必要としている人々を排除しています。

これらの教訓は、ハルト、ソラ、ユイ、ダイチ、サクラの話を聞くことから来ました。彼らが専門家です。私たちは単なる実装者です。」

---

## Slide 21: Future Work - The Journey Continues

**Speaker Notes (English):**

"So where do we go from here?

Immediate next steps: Field studies with real MOAI groups. Dr. Kotoku's KAKENHI grant will fund research with actual vulnerable communities. Not hypothetical personas—real people in real situations.

Formal safety verification. We need to prove mathematically that our bio-inspired consensus mechanisms have the safety properties we claim. This is where we need MASST community expertise.

Comprehensive accessibility evaluation with diverse disability communities. Daichi is one person. We need to test with blind users, deaf users, cognitive disabilities, motor disabilities—the full spectrum.

Additional language support. Japanese and English aren't enough. Korean, Chinese, Vietnamese—the languages of vulnerable immigrant communities in Japan and beyond.

Voice and avatar interaction for enhanced accessibility. Some people can't type. Some people can't see screens. We need multimodal interfaces that serve everyone.

But here's what we need from you—the MASST community:

How do we formally verify safety in bio-inspired consensus? What are the right frameworks?

What should standards look like for context-aware behavioral guardrails? How do we make this replicable?

How do we measure calibrated trust? What are the metrics that matter?

What ethical principles should guide AI for vulnerable populations? How do we codify 'do no harm' in multi-agent systems?

These aren't rhetorical questions. These are invitations to collaborate."

**発表者ノート（日本語）:**

「では、ここからどこへ行くのでしょうか？

直近の次のステップ：実際の模合グループでのフィールド研究。神徳教授のKAKENHI助成金は、実際の脆弱なコミュニティとの研究に資金を提供します。仮説的なペルソナではありません—実際の状況の実在の人々です。

形式的安全検証。私たちの生物触発型コンセンサスメカニズムが私たちが主張する安全性特性を持っていることを数学的に証明する必要があります。これは私たちがMASTコミュニティの専門知識を必要とするところです。

多様な障害コミュニティとの包括的なアクセシビリティ評価。ダイチは一人の人間です。盲目のユーザー、聴覚障害者のユーザー、認知障害、運動障害—完全なスペクトルでテストする必要があります。

追加の言語サポート。日本語と英語だけでは不十分です。韓国語、中国語、ベトナム語—日本内外の脆弱な移民コミュニティの言語。

強化されたアクセシビリティのための音声とアバターインタラクション。一部の人々はタイプできません。一部の人々は画面を見ることができません。全員にサービスを提供するマルチモーダルインターフェースが必要です。

しかし、ここであなた—MASTコミュニティ—から必要なものがあります：

生物触発型コンセンサスの安全性を形式的に検証する方法は？正しいフレームワークは何ですか？

文脈認識行動ガードレールの標準はどのように見えるべきですか？これを再現可能にする方法は？

較正された信頼をどのように測定しますか？重要なメトリクスは何ですか？

脆弱な人々のためのAIを導くべき倫理的原則は何ですか？マルチエージェントシステムで「害を与えない」をどのように成文化しますか？

これらは修辞的な質問ではありません。これらは協力への招待です。」

---

## Slide 22: Call to Action - Join Us

**Speaker Notes (English):**

"I stand before you not to present finished work, but to invite collaboration.

We need your expertise in formal verification. How do we prove safety properties in systems that blend social structure with AI?

We need your critical perspective. Where are the blind spots in our approach? What are we missing? What could go wrong?

We need your research partnerships. Cross-cultural adaptation studies—how does this work in non-Japanese contexts? In different social structures? With different vulnerable populations?

We need your standards expertise. The MASST community is uniquely positioned to help develop standards for multi-agent systems serving vulnerable populations.

But most importantly, we need your commitment to the principle that matters most: the people who need us most should drive our research priorities.

Not the people who can pay the most. Not the people who are easiest to serve. The people at the edges—the elderly, the disabled, the undocumented, the isolated, the discriminated against.

Because if we can make AI work for them, we'll have made AI work for everyone.

That's not just a technical challenge. It's a moral imperative.

Join us in building AI that serves humanity's most vulnerable. That's how we'll know we've truly solved multi-agent safety."

**発表者ノート（日本語）:**

「私は完成した作品を発表するためにここに立っているのではなく、協力を招待するためです。

形式的検証における専門知識が必要です。社会構造とAIを融合したシステムの安全性特性をどのように証明しますか？

批判的な視点が必要です。私たちのアプローチの盲点はどこですか？私たちは何を見逃していますか？何がうまくいかない可能性がありますか？

研究パートナーシップが必要です。異文化適応研究—これは非日本の文脈でどのように機能しますか？異なる社会構造で？異なる脆弱な人々で？

標準に関する専門知識が必要です。MASTコミュニティは、脆弱な人々にサービスを提供するマルチエージェントシステムの標準を開発するのを助けるのに独自の位置にあります。

しかし最も重要なことに、最も重要な原則へのコミットメントが必要です：私たちを最も必要としている人々が私たちの研究優先事項を推進すべきです。

最も支払うことができる人々ではありません。最も奉仕しやすい人々ではありません。エッジにいる人々—高齢者、障害者、非正規滞在者、孤立した人々、差別される人々。

なぜなら、彼らのためにAIを機能させることができれば、全員のためにAIを機能させたことになるからです。

それは単なる技術的課題ではありません。道徳的義務です。

人類の最も脆弱な人々に奉仕するAIの構築に参加してください。それが私たちがマルチエージェントの安全性を真に解決したことを知る方法です。」

---

## Slide 23: Conclusion - Where Centuries Meet Tomorrow

**Speaker Notes (English):**

"Let me bring us full circle. Back to that night. Back to Haruto.

He survived because five people cared. Because his community was there. Because 500 years of social technology met 21st-century artificial intelligence.

The AI didn't save Haruto. Keiko did. The AI just made her caring more effective.

That's the lesson. That's the paradigm shift. That's what we're offering the MASST community.

Not AI that replaces human community. AI that serves it. AI that augments it. AI that makes our caring more effective.

We've shown you what's possible. Real people. Real scenarios. Real architecture. Real implementation.

We've been honest about what's done and what's not. About the challenges ahead. About the questions we can't answer alone.

And we've invited you to join us. Because this is bigger than one research group. Bigger than one country. Bigger than one technology.

This is about whether artificial intelligence will serve humanity's most vulnerable—or fail them.

We believe it can serve them. We've shown you how. Now let's build it together.

Thank you."

**発表者ノート（日本語）:**

「完全な円に戻りましょう。あの夜に。ハルトに。

彼が生き延びたのは、5人が気にかけたからです。彼のコミュニティがそこにいたからです。500年の社会技術が21世紀の人工知能に出会ったからです。

AIはハルトを救いませんでした。恵子さんが救いました。AIは彼女の思いやりをより効果的にしただけです。

それが教訓です。それがパラダイムシフトです。それが私たちがMASTコミュニティに提供しているものです。

人間のコミュニティを置き換えるAIではありません。それに奉仕するAI。それを強化するAI。私たちの思いやりをより効果的にするAI。

私たちは何が可能かを示しました。実在の人々。実際のシナリオ。実際のアーキテクチャ。実際の実装。

私たちは何が完了し、何が完了していないかについて正直でした。今後の課題について。私たちだけでは答えられない質問について。

そして私たちはあなたを参加に招待しました。なぜなら、これは一つの研究グループよりも大きいからです。一つの国よりも大きい。一つの技術よりも大きい。

これは、人工知能が人類の最も脆弱な人々に奉仕するか、それとも彼らを失望させるかについてです。

私たちはそれが彼らに奉仕できると信じています。私たちはその方法を示しました。今一緒にそれを構築しましょう。

ありがとうございました。」

---

## Slide 24: Thank You & Let's Connect

**Speaker Notes (English):**

"Please, come talk to us. During the breaks. After the session. Over coffee.

We have a live demo available. Watch Haruto's emergency scenario play out in real-time. See the dashboard. Try the accessibility features. Ask the hard questions.

If you want to collaborate on formal verification, we need you. If you have expertise in cross-cultural adaptation, we need you. If you work with vulnerable populations and can help us test and refine, we desperately need you.

This is Dr. Kotoku's contact information—she's leading the field studies with nursing communities. This is Dr. Miyazaki—disability studies and accessibility expertise. And I'm Yuri Tijerino—the technical architecture and implementation.

The AIngle DLT platform is on GitHub. The code is there. The documentation is there. The benchmarks are there. This is open research.

We're not selling you anything. We're inviting you into something.

Let's build AI that serves the people who need it most. Let's build it together. Let's build it right.

Thank you for listening to our story. Now let's write the next chapter together."

**発表者ノート（日本語）:**

「どうぞ、私たちに話しかけてください。休憩中。セッション後。コーヒーを飲みながら。

ライブデモが利用可能です。ハルトの緊急シナリオがリアルタイムで展開するのを見てください。ダッシュボードを見てください。アクセシビリティ機能を試してください。難しい質問をしてください。

形式的検証で協力したい場合、私たちはあなたを必要としています。異文化適応の専門知識がある場合、私たちはあなたを必要としています。脆弱な人々と働いていて、テストと改良を手伝ってくれる場合、私たちは切実にあなたを必要としています。

これは神徳教授の連絡先です—彼女は看護コミュニティでのフィールド研究を主導しています。これは宮崎教授—障害研究とアクセシビリティの専門知識。そして私はティヘリノ　ジュリ—技術アーキテクチャと実装。

AIngle DLTプラットフォームはGitHubにあります。コードがあります。ドキュメントがあります。ベンチマークがあります。これはオープンリサーチです。

私たちは何も売っていません。私たちは何かにあなたを招待しています。

最も必要としている人々に奉仕するAIを構築しましょう。一緒にそれを構築しましょう。正しく構築しましょう。

私たちの物語を聞いてくださってありがとうございます。今一緒に次の章を書きましょう。」

---

## Presentation Delivery Tips | プレゼンテーション実施のコツ

**English:**

**Voice and Pacing:**
- Start quietly with Haruto's story (build tension)
- Speed up slightly during the crisis moments
- Slow down for the key insights and lessons
- End with quiet confidence and invitation

**Emotional Beats:**
- Slide 2 (Haruto's crisis): Fear and urgency
- Slide 3 (The problem): Anger and frustration at failures
- Slide 4 (MOAI inspiration): Wonder and hope
- Slide 8 (Yui's journey): Compassion and patience
- Slide 14 (Privacy): Righteous conviction
- Slide 20 (Lessons): Humility and learning
- Slide 23 (Conclusion): Determination and invitation

**Eye Contact:**
- Look at audience during stories (Haruto, Yui, Sora)
- Look at slides during technical details
- Look at audience during questions and conclusion

**Hand Gestures:**
- Small circle for "5 people" (emphasize the limit)
- Outward palms for "human primacy" (openness)
- Hands together for "community" (connection)
- Open arms for "join us" (invitation)

**日本語:**

**声とペース:**
- ハルトの物語で静かに始める（緊張を構築）
- 危機の瞬間で少し速くする
- 重要な洞察と教訓でゆっくりにする
- 静かな自信と招待で終わる

**感情的なビート:**
- スライド2（ハルトの危機）：恐怖と緊急性
- スライド3（問題）：失敗への怒りとフラストレーション
- スライド4（模合のインスピレーション）：驚きと希望
- スライド8（ユイの旅）：思いやりと忍耐
- スライド14（プライバシー）：正義の確信
- スライド20（教訓）：謙虚さと学び
- スライド23（結論）：決意と招待

**アイコンタクト:**
- 物語の間、聴衆を見る（ハルト、ユイ、ソラ）
- 技術的詳細の間、スライドを見る
- 質問と結論の間、聴衆を見る

**ハンドジェスチャー:**
- 「5人」のための小さな円（制限を強調）
- 「人間の優位性」のための外向きの手のひら（開放性）
- 「コミュニティ」のための一緒の手（つながり）
- 「参加してください」のための開いた腕（招待）

---

**Document Type:** Narrative-Driven Speaker Notes
**文書タイプ:** ナラティブ駆動の発表者ノート

**Purpose:** To tell a memorable story that connects emotionally with the MASST audience while delivering technical content
**目的:** 技術的内容を提供しながらMAST聴衆と感情的につながる記憶に残る物語を語ること

**Total Speaking Time:** 18-20 minutes (without Q&A)
**総発表時間:** 18-20分（質疑応答なし）
