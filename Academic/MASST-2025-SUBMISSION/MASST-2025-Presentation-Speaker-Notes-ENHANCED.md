# Digital MOAI: Presentation Speaker Notes - ENHANCED
# デジタル模合：プレゼンテーション発表者ノート - 強化版

**A Story-Driven Narrative Journey Enhanced with Creative Writing Techniques**
**創作技法で強化されたストーリー駆動のナラティブジャーニー**

---

## Slide 1: Title - Opening the Door

**Speaker Notes (English):**

"Good morning. Before I tell you about our research, I want you to feel something.

*[Pause. Let silence build.]*

The smell of instant ramen. Cold. Forgotten on a kitchen table. The blue-white glow of a phone screen reflecting off cheap laminate at 11:47 PM.

Haruto Tanaka wakes to pain—not sharp, but spreading. Like fingers pressing into his chest, squeezing. Seventy-four years old. The apartment still smells like Michiko's perfume, though she's been gone two years. His children's voices are recordings on his phone. Osaka is only three hours away by train. It might as well be the moon.

In this moment, Haruto makes the calculation all elderly people living alone eventually make: Is this nothing? Or is this the end?

*[Pause. Make eye contact.]*

This presentation isn't about technology. It's about the three minutes between Haruto's chest pain starting and help arriving. It's about whether artificial intelligence can close that gap—or whether it will widen it.

I'm Yuri Tijerino from Kwansei Gakuin University. My colleagues—Dr. Kazuko Kotoku from Fukuoka University and Dr. Yasushi Miyazaki—we've been asking one question that haunts us: How do we build AI systems for the people AI most often forgets?

The answer wasn't in Silicon Valley. It wasn't buried in neural networks. It was in Okinawa, in the wrinkled hands of Dr. Kotoku's 96-year-old grandmother, alive and vibrant through a tradition that's kept people breathing for 500 years."

**発表者ノート（日本語）:**

「おはようございます。私たちの研究についてお話しする前に、何かを感じてほしいのです。

*[間を取る。沈黙を築く。]*

インスタントラーメンの匂い。冷たい。キッチンテーブルの上に忘れられている。午後11時47分、安っぽいラミネートに反射するスマートフォンの青白い輝き。

田中ハルトは痛みで目を覚まします—鋭いものではなく、広がるもの。指が胸を押し、絞るように。74歳。アパートはまだ美智子さんの香水の匂いがします。彼女が亡くなって2年経っているのに。子供たちの声は電話の録音です。大阪は電車でたった3時間。月と同じくらい遠い。

この瞬間、ハルトは一人暮らしのすべての高齢者がいつかする計算をします：これは何でもない？それとも、これが終わり？

*[間を取る。アイコンタクト。]*

このプレゼンテーションは技術についてではありません。ハルトの胸の痛みが始まってから助けが到着するまでの3分間についてです。人工知能がその隙間を閉じることができるのか、それとも広げるのか、についてです。

私は関西学院大学のティヘリノ　ジュリです。私の同僚—福岡大学の神徳和子教授と宮崎康教授—私たちを悩ませる一つの問いを追求してきました：AIが最もよく忘れる人々のためのAIシステムをどう構築するか？

答えはシリコンバレーにはありませんでした。ニューラルネットワークの中に埋もれてもいませんでした。それは沖縄にありました。神徳教授の96歳の祖母のしわの寄った手の中に。500年間人々を呼吸させ続けてきた伝統を通じて、生き生きと活発に。」

---

## Slide 2: Meet Haruto - The Crisis Unfolds

**Speaker Notes (English):**

"Let me take you inside that moment.

Haruto's kitchen table is small—meant for two, now set for one. The pain radiates from his sternum like cracks in ice. His left arm tingles. He knows what this is. He's a retired accountant; he understands probability, risk, consequence.

But knowledge and action are separated by fear.

His phone lies face-down beside the cold ramen. The termination letter from his part-time job at the convenience store is still open on the table. 'Thank you for your service. Economic conditions. We regret...' At seventy-four, being useful was the thing keeping the loneliness at bay.

Now this. The pain. The fear. The shameful thought: *What if I'm wrong? What if it's just stress? What if I call an ambulance and it's nothing and I waste everyone's time and money and they'll think I'm just a scared old man and maybe I am and—*

His hand shakes. Not from the heart attack. From the paralysis of being alone.

But there's something on his phone Michiko would have loved. Something his daughter set up last month, patient despite his fumbling. 'Papa, just one button. Red button. That's all.'

He taps it.

What happens next isn't magic. It's what happens when you design with one ghost haunting every decision: the ghost of Haruto dying alone on his kitchen floor while his phone screen goes dark.

*0.3 seconds:* The app pulls his medical file from encrypted local storage. Atrial fibrillation. Blood thinner medications. Penicillin allergy. The stent surgery three years ago.

*1.8 seconds:* Four phones light up. Keiko Yamamoto, 67, his neighbor in 3B. Takeshi Suzuki, 71, three buildings over. Yumiko Tanaka (no relation), 69. Hiroshi Nakamura, 76, who walks with a cane but still comes to Tuesday tea.

*2.0 seconds:* Emergency services receive a formatted alert. Location. Medical history. 'Suspected cardiac event. Patient conscious. No trauma.'

Keiko sees the alert. She's in her nightgown, reading glasses on, TV remote in hand. She doesn't change clothes. She runs.

By the time the ambulance arrives—sirens carving through the Tokyo night—Keiko is holding Haruto's hand. Her palm is warm, dry, certain. Haruto's is cold and trembling.

'Foolish,' he whispers.
'You're here,' she says. 'That's not foolish.'

The paramedic takes the tablet from Keiko's other hand. Haruto's complete medical history. Current medications. Allergies. The stent surgery. No fumbling. No dangerous gaps. No time wasted while a seventy-four-year-old man tries to remember drug names through the fog of fear and hypoxia.

Haruto survives that night.

But understand this—millions like Haruto don't. Not because the technology doesn't exist. Because current AI systems treat people like data points, not like someone's father who still smells his dead wife's perfume and measures his worth by whether he's useful."

**発表者ノート（日本語）:**

「その瞬間の中にお連れしましょう。

ハルトのキッチンテーブルは小さい—2人用のはずが、今は1人用。痛みは胸骨から氷のひび割れのように放射します。左腕がうずきます。彼はこれが何かわかっています。彼は引退した会計士です。確率、リスク、結果を理解しています。

しかし知識と行動は恐怖によって分離されています。

彼の電話は冷たいラーメンの横に伏せて置かれています。コンビニエンスストアのパートタイムの仕事からの解雇通知はまだテーブルの上に開かれています。「ご尽力ありがとうございました。経済状況。残念ながら...」74歳で、役に立つことが孤独を寄せ付けないものでした。

そして今これ。痛み。恐怖。恥ずかしい思い：*もし間違っていたら？もしこれがただのストレスだったら？もし救急車を呼んでそれが何でもなくて、みんなの時間とお金を無駄にして、彼らは私がただの怖がっている老人だと思うだろう。そしてたぶん私はそうで—*

彼の手が震えます。心臓発作のせいではなく、一人でいることの麻痺のせい。

しかし彼の電話には美智子さんが好きだったであろう何かがあります。先月娘が設定した何か、彼の不器用さにもかかわらず辛抱強く。「パパ、ボタン一つだけ。赤いボタン。それだけ。」

彼はそれをタップします。

次に起こることは魔法ではありません。すべての決定を悩ませる一つの幽霊、キッチンの床で一人で死んでいくハルトの幽霊、彼の電話画面が暗くなっている間に、その幽霊を抱えて設計したときに起こることです。

*0.3秒:* アプリは暗号化されたローカルストレージから彼の医療ファイルを引き出します。心房細動。血液希釈薬。ペニシリンアレルギー。3年前のステント手術。

*1.8秒:* 4つの電話が光ります。山本恵子さん、67歳、3Bの隣人。鈴木武さん、71歳、3棟向こう。田中由美子さん（関係なし）、69歳。中村宏さん、76歳、杖をついて歩くが、まだ火曜日のお茶に来る。

*2.0秒:* 緊急サービスはフォーマットされたアラートを受け取ります。位置。病歴。「心臓イベントの疑い。患者意識あり。外傷なし。」

恵子さんはアラートを見ます。彼女はナイトガウン姿、老眼鏡をかけ、テレビのリモコンを手に。彼女は服を着替えません。走ります。

救急車が到着するまでに—サイレンが東京の夜を切り裂く—恵子さんはハルトの手を握っています。彼女の手のひらは温かく、乾いていて、確信に満ちています。ハルトのは冷たく震えています。

「ばかげている」と彼はささやきます。
「あなたはここにいます」と彼女は言います。「それはばかげていません。」

救急隊員は恵子さんのもう一方の手からタブレットを受け取ります。ハルトの完全な病歴。現在の薬。アレルギー。ステント手術。もたつきなし。危険なギャップなし。74歳の男性が恐怖と低酸素の霧の中で薬の名前を思い出そうとする間に無駄にする時間なし。

ハルトはその夜生き延びます。

しかし理解してください—ハルトのような何百万もの人々はそうではありません。技術が存在しないからではありません。現在のAIシステムが人々をデータポイントとして扱うからです。死んだ妻の香水の匂いをまだ嗅ぎ、自分が役に立つかどうかで価値を測る誰かの父親としてではなく。」

---

## Slide 3: The Problem - When AI Fails

**Speaker Notes (English):**

"Haruto's story has a happy ending. Let me show you what happens when the system is designed wrong.

*[Voice shifts—harder, more urgent]*

Her name is Maria. Not Sora—that came later, the name she chose when she needed to disappear.

Twenty-five years old. The apartment in Ikebukuro smells like fish and industrial cleaner. She works the early shift at a family restaurant, the late shift cleaning offices. Thirteen-hour days. The money goes home to the Philippines—her mother's medication, her brother's school fees.

When the landlord sees her visa has expired, the eviction notice is taped to her door. Three days.

She needs help. She finds a nonprofit with a gleaming website. 'AI-powered assistance for immigrant communities.' It asks for her name. Passport number. Employment history. Banking records. The interface is friendly, encouraging. 'We're here to help.'

She uploads everything.

Six months later, the database is breached. Her information is sold. Not to criminals—to Immigration. The file includes her apartment address, her work schedule, the 7-Eleven where she buys her morning coffee.

They take her on a Tuesday morning. She has ¥3,200 in her purse. Her phone battery is at 43%. Her children—born in Japan, citizens—watch their mother put into a van.

Maria is now in Manila. Her children are in foster care. The nonprofit issued an apology. 'We regret this unfortunate incident. We have upgraded our security protocols.'

*[Pause. Let the weight settle.]*

Or Sakura. Thirty-one. Transgender. Seven years into her transition. Her medical records are private, encrypted, safe—until they're not. A breach. A leak. Her deadname shows up in search results attached to her current legal name.

The violence is swift. The housing discrimination immediate. The job she loved—gone. The AI system that was supposed to protect her privacy became the weapon that destroyed it.

Or Yui. Twenty-two. Her room is small—six tatami mats. The door hasn't opened in two years except for food deliveries left outside. Social anxiety disorder, the doctors said. But that diagnosis doesn't capture the physics of it—the way opening the door feels like gravity reversed, like stepping into freefall.

Well-meaning chatbots message her. 'Have you tried going outside?' 'Just take small steps!' 'You can do it!'

She mutes them all. They don't understand that for her, 'just' is the cruelest word in any language.

*[Voice softens but remains firm]*

Current AI systems fail these people not through malice but through design. They were built for average users in average situations. They optimize for efficiency over safety. They centralize data, creating single points of catastrophic failure. They lack cultural awareness—translating words without understanding worlds. They ignore accessibility, making perfection the enemy of participation.

For vulnerable populations, these aren't bugs. They're existential threats. And AI failures aren't inconveniences—they're life sentences."

**発表者ノート（日本語）:**

「ハルトの物語はハッピーエンドです。システムが間違って設計されたときに何が起こるかお見せしましょう。

*[声を変える—より硬く、より緊急に]*

彼女の名前はマリアです。ソラではありません—それは後に来ました、彼女が消える必要があったときに選んだ名前。

25歳。池袋のアパートは魚と工業用洗剤の匂いがします。彼女はファミリーレストランで早番、オフィス清掃で遅番で働きます。13時間の日々。お金はフィリピンの実家に行きます—母親の薬、弟の学費。

家主が彼女のビザが切れているのを見ると、立ち退き通知がドアに貼られます。3日間。

彼女は助けを必要としています。彼女は輝くウェブサイトを持つ非営利団体を見つけます。「移民コミュニティのためのAI駆動支援。」それは彼女の名前を尋ねます。パスポート番号。雇用履歴。銀行記録。インターフェースは親しみやすく、励まします。「私たちはあなたを助けるためにここにいます。」

彼女はすべてをアップロードします。

6ヶ月後、データベースが侵害されます。彼女の情報は売られます。犯罪者にではなく—入国管理局に。ファイルには彼女のアパートの住所、勤務スケジュール、朝のコーヒーを買うセブンイレブンが含まれています。

彼らは火曜日の朝に彼女を連れて行きます。彼女の財布には3,200円。携帯電話のバッテリーは43%。彼女の子供たち—日本で生まれた市民—母親がバンに入れられるのを見ます。

マリアは今マニラにいます。彼女の子供たちは里親養育にいます。非営利団体は謝罪を発表しました。「この不幸な事件を遺憾に思います。セキュリティプロトコルをアップグレードしました。」

*[間を取る。重みを沈める。]*

あるいはサクラ。31歳。トランスジェンダー。移行して7年。彼女の医療記録はプライベート、暗号化され、安全—安全でなくなるまでは。侵害。漏洩。彼女の旧名が検索結果に現在の法的名前と一緒に表示されます。

暴力は迅速です。住宅差別は即座。彼女が愛した仕事—なくなりました。彼女のプライバシーを保護するはずだったAIシステムは、それを破壊した武器になりました。

あるいはユイ。22歳。彼女の部屋は小さい—六畳。ドアは2年間、外に残された食べ物の配達以外開いていません。社交不安障害、医者は言いました。しかしその診断はそれの物理学を捉えていません—ドアを開けることが重力が逆転したように感じる方法、自由落下に踏み出すように。

善意のチャットボットが彼女にメッセージを送ります。「外に出てみましたか？」「小さなステップを踏むだけです！」「あなたはできます！」

彼女はすべてをミュートします。彼らは理解していません。彼女にとって「ただ」がどの言語でも最も残酷な言葉であることを。

*[声を和らげるが、しっかりと保つ]*

現在のAIシステムがこれらの人々を失望させるのは、悪意によってではなく設計によってです。彼らは平均的なユーザーの平均的な状況のために構築されました。安全性より効率性を最適化します。データを集中化し、壊滅的な障害の単一点を作ります。文化的認識が欠けています—世界を理解せずに言葉を翻訳します。アクセシビリティを無視し、完璧を参加の敵にします。

脆弱な人々にとって、これらはバグではありません。存続の脅威です。そしてAIの失敗は不便ではありません—終身刑です。」

---

## Slide 4: The Inspiration - 500 Years of Wisdom

**Speaker Notes (English):**

"When we started this project, we fell into the trap every researcher falls into.

We read papers. RLHF. Constitutional AI. Anthropic's harmlessness training. We tried to engineer safety in isolation, then deploy it to messy human reality. Like building a boat in a basement and being surprised when it doesn't float.

Then Dr. Kotoku told us about her grandmother.

Ninety-six years old. Lives in Okinawa. Has never been hospitalized for a major illness. Mentally sharp enough to beat Dr. Kotoku at hanafuda cards. Physically active—still tends her small garden, still walks to the market. Happy in a way that seems almost defiant of age and loss and time.

The secret? Five people.

Her MOAI—模合—the same five people for seventy-three years. Through births and deaths. Through celebrations and catastrophes. Through the American occupation and economic bubbles and the long erosion of traditional life.

They meet every week. Same day. Same time. No calendar invites. No reminders. It's woven into their weeks like breathing.

They pool money for emergencies—not in banks, but in a shared fund they manage collectively. When someone needs surgery, the money is there. When someone's grandchild needs school fees, the money is there. No interest rates. No credit checks. No algorithm deciding who deserves help.

They support each other emotionally. Practically. With the kind of knowledge that only comes from seventy-three years of showing up—knowing that Grandmother Kotoku takes her tea with two sugars and no milk, that she gets anxious during typhoon season because of what happened in 1978, that she doesn't like to be alone after dark not because she's afraid of criminals but because that's when she misses her late husband most.

*[Pause. Make this land.]*

And here's what made us stop everything and start over: the five-person limit isn't arbitrary.

Five is small enough to build real trust. Small enough to know everyone intimately—not their data profile, but their ghosts, their wounds, their defense mechanisms. Small enough that betrayal has weight, that accountability is personal, that care doesn't scale into bureaucracy.

Five is small enough that privacy is natural. There's no surveillance at scale. No data aggregation. No honeypot for hackers. No system worth subpoenaing.

Five hundred years of social technology. Proven not in labs but in lives lived. Documented by the Okinawa Centenarian Study as a key factor in the longest lifespans on Earth.

We asked ourselves: What if we stopped trying to replace this with AI? What if we augmented it? What if the technology served the human structure instead of dissolving it?

What if the wisdom was already there, waiting for us to be humble enough to see it?"

**発表者ノート（日本語）:**

「このプロジェクトを始めたとき、私たちはすべての研究者が陥る罠に陥りました。

私たちは論文を読みました。RLHF。Constitutional AI。Anthropicの無害性訓練。私たちは孤立して安全性を工学的に設計しようとし、それから混乱した人間の現実に展開しようとしました。地下室でボートを作り、それが浮かばないことに驚くように。

それから神徳教授は彼女の祖母のことを話してくれました。

96歳。沖縄に住んでいます。大きな病気で入院したことがありません。神徳教授を花札で負かすほど精神的にシャープ。身体的に活動的—まだ小さな庭の世話をし、まだ市場に歩いて行きます。年齢と喪失と時間に対してほとんど反抗的に見える方法で幸せ。

秘訣は？5人。

彼女の模合—73年間同じ5人。誕生と死を通じて。祝いと災害を通じて。アメリカ占領と経済バブルと伝統的生活の長い浸食を通じて。

彼らは毎週会います。同じ日。同じ時間。カレンダーの招待なし。リマインダーなし。呼吸のように彼らの週に織り込まれています。

彼らは緊急時のためにお金を出し合います—銀行ではなく、彼らが集団的に管理する共有基金で。誰かが手術を必要とするとき、お金はそこにあります。誰かの孫が学費を必要とするとき、お金はそこにあります。金利なし。信用チェックなし。誰が助けに値するかを決定するアルゴリズムなし。

彼らはお互いを感情的にサポートします。実践的に。73年間現れることからしか来ない知識の種類で—神徳おばあさんがお茶を砂糖2つとミルクなしで取ること、1978年に何があったために台風の季節に不安になること、犯罪者が怖いのではなく、それが彼女が亡くなった夫を最も恋しく思う時だから、暗くなった後一人でいるのを好まないことを知っています。

*[間を取る。これを着地させる。]*

そして私たちにすべてを止めてやり直させたものはこれです：5人の制限は恣意的ではありません。

5は本当の信頼を築くのに十分小さい。全員を親密に知るのに十分小さい—彼らのデータプロファイルではなく、彼らの幽霊、彼らの傷、彼らの防衛機制。裏切りが重みを持つほど十分小さい、説明責任が個人的である、ケアが官僚制にスケールしない。

5はプライバシーが自然であるほど十分小さい。大規模な監視なし。データ集約なし。ハッカーのためのハニーポットなし。召喚状の価値があるシステムなし。

500年の社会技術。実験室ではなく生きられた人生で実証されました。地球上で最も長い寿命の重要な要因として沖縄百寿者研究によって文書化されています。

私たちは自問しました：これをAIで置き換えようとすることを止めたらどうだろう？それを強化したらどうだろう？技術が人間の構造を溶解する代わりにそれに奉仕するとしたらどうだろう？

知恵がすでにそこにあって、私たちがそれを見るほど謙虚になるのを待っているとしたらどうだろう？」

---

## Slide 5: The Vision - Augmentation, Not Replacement

**Speaker Notes (English):**

"Let me paint this for you. Close your eyes if you need to—let me make you see it.

Tuesday afternoon. The community center in Setagaya ward. Sunlight through cheap curtains, dust motes floating. The smell of green tea and the sweet bean paste from someone's gift of mochi.

Five people around a low table. Haruto. Keiko. Takeshi. Yumiko. Hiroshi.

This is Shinrai MOAI—Trust MOAI. They've been meeting here for three years. They still make tea together. Still discuss how to split the emergency fund contributions. Still gossip about their grandchildren and complain about the weather and laugh at jokes that only make sense to people who've earned the right to laugh at each other.

But now, there's augmentation.

Haruto pulls out his phone—the screen adjusts instantly. Large text. High contrast. The font his aging eyes can actually read without squinting. His personal AI knows he prefers formal Japanese. It knows his medication schedule. It knows he gets anxious when his daughter doesn't call, so it doesn't bombard him with notifications—it waits, it watches, it learns when to speak and when to be silent.

Keiko uses voice control. Arthritis makes typing painful, so she talks to her phone like a patient friend. The AI understands her regional accent, her speech patterns, the way she trails off when she's thinking.

The group coordinator AI—they've named it Mamoru, which means 'protector'—handles the boring logistics. It notices that Takeshi hasn't checked in for two days. It suggests the Tuesday meeting venue should have wheelchair access because Hiroshi's knee is acting up. It doesn't demand. It doesn't nag. It suggests, with transparent reasoning they can accept or override.

The accessibility layer adapts to each person. For Haruto: large text, simplified interface. For Keiko: voice-first interaction. For members with cognitive changes: 'Easy Japanese' mode that doesn't condescend but clarifies.

And critically—invisibly until needed—the emergency response coordinator. The thing that saved Haruto's life.

*[Pause. Voice firm.]*

But here's the key, the non-negotiable principle: The AI suggests. The humans decide. Always.

The five members vote collectively on automation policies. How much should Mamoru do automatically? When should it escalate to humans? What's private to individuals and what's shared with the group?

Haruto can't opt Keiko into high automation. Keiko can't force the group to adopt features she likes. This is collective governance. This is democracy at the scale where democracy actually works—small enough to see each other's faces when you disagree.

The traditional MOAI structure provides natural guardrails—the social architecture that's kept people safe for five centuries. The AI provides superhuman coordination—instant communication, accessible interfaces, emergency response.

Together, they create something neither could achieve alone: technology that serves humanity instead of replacing it."

**発表者ノート（日本語）:**

「これを描かせてください。必要なら目を閉じてください—私にそれを見せさせてください。

火曜日の午後。世田谷区のコミュニティセンター。安っぽいカーテンを通した日光、浮かぶ塵の粒子。緑茶の匂いと誰かのもちの贈り物からの甘い餡。

低いテーブルの周りに5人。ハルト。恵子。武。由美子。宏。

これは信頼模合。彼らはここで3年間会っています。まだ一緒にお茶を作ります。まだ緊急基金の拠出をどう分けるか話し合います。まだ孫について噂話し、天気について文句を言い、お互いを笑う権利を得た人々にのみ意味のある冗談で笑います。

しかし今、増強があります。

ハルトは電話を取り出します—画面は即座に調整されます。大きなテキスト。高コントラスト。彼の老化した目が目を細めずに実際に読めるフォント。彼の個人AIは彼が丁寧な日本語を好むことを知っています。彼の薬のスケジュールを知っています。娘が電話しないときに不安になることを知っているので、通知で彼を爆撃しません—待ち、見守り、いつ話し、いつ沈黙するかを学びます。

恵子さんは音声制御を使います。関節炎でタイプが痛いので、彼女は辛抱強い友人のように電話に話しかけます。AIは彼女の地域のアクセント、彼女の話し方、彼女が考えているときに言葉を濁らす方法を理解します。

グループコーディネーターAI—彼らはそれをマモル、「保護者」を意味すると名付けました—退屈な物流を処理します。武さんが2日間チェックインしていないことに気づきます。宏さんの膝が痛いので、火曜日の会議会場は車椅子アクセス可能であるべきだと提案します。要求しません。うるさくしません。提案します、彼らが受け入れるかオーバーライドできる透明な推論で。

アクセシビリティレイヤーは各人に適応します。ハルトのため：大きなテキスト、簡略化されたインターフェース。恵子さんのため：音声ファーストインタラクション。認知変化のあるメンバーのため：見下さないが明確化する「やさしい日本語」モード。

そして重要なこと—必要になるまで見えない—緊急対応コーディネーター。ハルトの命を救ったもの。

*[間を取る。声をしっかりと。]*

しかしここが鍵です、譲れない原則：AIは提案します。人間が決定します。常に。

5人のメンバーは自動化ポリシーについて集団的に投票します。マモルはどれだけ自動的にすべきか？いつ人間にエスカレートすべきか？何が個人にプライベートで何がグループと共有されるか？

ハルトは恵子さんを高い自動化に参加させることはできません。恵子さんは彼女が好きな機能を採用するようグループを強制できません。これは集団的ガバナンスです。これは民主主義が実際に機能するスケールでの民主主義です—同意しないときにお互いの顔を見るのに十分小さい。

伝統的な模合構造は自然なガードレールを提供します—5世紀間人々を安全に保ってきた社会アーキテクチャ。AIは超人的な調整を提供します—即座の通信、アクセス可能なインターフェース、緊急対応。

一緒に、彼らはどちらも単独では達成できない何かを創造します：人類を置き換えるのではなく奉仕する技術。」

---

## Slide 6: Live Demo - See It Work

**Speaker Notes (English):**

"What you're seeing isn't a mockup. This is real.

*[Touch the screen—let them see you interact with it]*

The Tokyo Community Builders MOAI dashboard. Five members. Names, not user IDs. Faces, not avatars generated by AI. Real people who chose to trust each other.

The emergency fund: ¥50,000. Not managed by a corporation in California. Not stored on a server that can be subpoenaed. This money belongs to the MOAI—a legally incorporated entity with its own rights, its own bank account, its own legal standing.

Yes. Each MOAI is legally incorporated. It can hold assets. Sign contracts. Protect its members' privacy while interfacing with systems that require organizational identity. When Jiyuu MOAI signs a lease for emergency housing, the landlord sees the organization, not Sora's expired visa.

Look at the navigation. Chat. Activities. Media. Finance. AI Assistant. Simple enough for Haruto to navigate without anxiety. Powerful enough to coordinate emergency response in under two seconds.

This runs on the AIngle DLT platform we've built. Not blockchain—that's too slow, too energy-intensive, too much hype. This is distributed ledger technology optimized for real-time human needs.

Everything is local-first. When you send a message in this chat, it doesn't go to the cloud. It goes directly to your MOAI members' devices, encrypted peer-to-peer. If you're offline, it queues. When you reconnect, it syncs. No central server. No single point of failure. No company that can be breached, sold, or subpoenaed.

The interface adapts. Watch—

*[Demonstrate if possible, or describe vividly]*

If you're Daichi with cerebral palsy, you get voice control. Simplified gestures. You speak: 'Mamoru, when is the next meeting?' The system responds without requiring you to aim your trembling hand at tiny touch targets.

If you're Haruto with aging eyes, you get high contrast. Larger text. Clear icons. The interface knows you need more time to read, so notifications don't vanish after three seconds.

If you're Yui with social anxiety, you can participate through text without ever showing your face. The camera stays off unless you choose otherwise. The system never pressures you to 'turn your camera on for a better experience.'

This is what happens when you design for the most vulnerable first. The accessibility features that save Daichi's participation make everyone's experience better. The privacy protections that keep Sora safe protect everyone. The gentle pacing that helps Yui engage reduces everyone's stress.

Design for the edges. Improve the center."

**発表者ノート（日本語）:**

「あなたが見ているものはモックアップではありません。これは本物です。

*[画面に触れる—彼らにあなたがそれと対話するのを見せる]*

東京コミュニティビルダーズ模合ダッシュボード。5人のメンバー。ユーザーIDではなく名前。AIによって生成されたアバターではなく顔。お互いを信頼することを選んだ実在の人々。

緊急基金：50,000円。カリフォルニアの企業によって管理されていません。召喚状を受けることができるサーバーに保存されていません。このお金は模合に属します—自分自身の権利、自分自身の銀行口座、自分自身の法的地位を持つ法的に設立された組織。

はい。各模合は法的に設立されています。資産を保有できます。契約に署名できます。組織アイデンティティを必要とするシステムとインターフェースしながらメンバーのプライバシーを保護できます。自由模合が緊急住宅のためにリースに署名するとき、家主は組織を見ます、ソラの期限切れビザではありません。

ナビゲーションを見てください。チャット。活動。メディア。会計。AIアシスタント。ハルトが不安なしにナビゲートするのに十分シンプル。2秒未満で緊急対応を調整するのに十分強力。

これは私たちが構築したAIngle DLTプラットフォームで動作します。ブロックチェーンではありません—それは遅すぎる、エネルギー集約的すぎる、誇大広告が多すぎる。これはリアルタイムの人間のニーズのために最適化された分散台帳技術です。

すべてがローカルファーストです。このチャットでメッセージを送信するとき、それはクラウドに行きません。あなたの模合メンバーのデバイスに直接行き、ピアツーピアで暗号化されます。オフラインの場合、キューに入ります。再接続すると、同期します。中央サーバーなし。単一の障害点なし。侵害され、売られ、または召喚状を受けることができる会社なし。

インターフェースは適応します。見てください—

*[可能であれば実演、または鮮明に説明]*

脳性麻痺のダイチなら、音声制御を取得します。簡略化されたジェスチャー。あなたは話します：「マモル、次の会議はいつ？」システムは震える手を小さなタッチターゲットに向ける必要なしに応答します。

老化した目のハルトなら、高コントラストを取得します。より大きなテキスト。明確なアイコン。インターフェースはあなたが読むのにより多くの時間を必要とすることを知っているので、通知は3秒後に消えません。

社交不安のあるユイなら、顔を見せずにテキストで参加できます。カメラはあなたが選択しない限りオフのままです。システムは「より良い体験のためにカメラをオンにする」ようにあなたに圧力をかけません。

これは最も脆弱な人々のために最初に設計したときに起こることです。ダイチの参加を救うアクセシビリティ機能は全員の体験をより良くします。ソラを安全に保つプライバシー保護は全員を保護します。ユイが関与するのを助ける穏やかなペースは全員のストレスを減らします。

エッジのために設計してください。センターを改善してください。」

---

## Slide 7: Five Real MOAIs - Five Lives

**Speaker Notes (English):**

"We're not building one MOAI. We're building five. Because vulnerability isn't monolithic—it's fractured, intersectional, specific.

*[Voice shifts for each persona—make them distinct]*

**Shinrai MOAI—Trust MOAI.**
For people like Haruto. Seventy-four. Widowed. Living alone in an apartment that still smells like his wife's perfume. The ghost he carries: obsolescence. He was useful once—balanced books, supported a family, mattered. Now? A part-time job lost. Children in another city. The fear that dying alone is the price of aging.

His want: Safety. Medical emergencies handled. Scams avoided.
His need: To still matter. To still be part of something. To be seen.

**Mirai MOAI—Future MOAI.**
For people like Daichi. Twenty-eight. Cerebral palsy. Wheelchair user. Brilliant mind trapped in a body that doesn't obey.

The ghost he carries: Burden. The voice that says he's an inconvenience, that accessibility is a favor people grant rather than a right he possesses.

His want: To attend community events. To participate fully. To be included.
His need: To be designed for, not accommodated after the fact. To have his expertise recognized.

**Kibou MOAI—Hope MOAI.**
For people like Yui. Twenty-two. Her room: six tatami mats. The door: closed for two years. The window: covered. The world: too loud, too bright, too much.

The ghost she carries: Judgment. The certainty that if she goes outside, everyone will see how broken she is.

Her defense mechanism: Withdrawal. If you can't fail, you can't be hurt.

Her want: To stop feeling so alone.
Her need: To learn that healing isn't linear, that participation doesn't require perfection, that she's not broken—just wounded.

**Yuiitsu MOAI—Unique MOAI.**
For people like Sakura. Thirty-one. Seven years into transition. Her true self finally visible—and therefore vulnerable.

The ghost she carries: Exposure. The database breach. Her deadname attached forever to her legal name in search results. The violence that followed.

Her defense mechanism: Hypervigilance. Trust no system. Encrypt everything. Disappear when necessary.

Her want: Safety from discrimination and violence.
Her need: To exist without hiding. To be seen without being endangered.

**Jiyuu MOAI—Freedom MOAI.**
For people like Sora. Twenty-five. Undocumented. Two jobs. Thirteen-hour days. Money sent home. Visa expired.

The ghost she carries: Her friend Maria. Deported. Children in foster care. The nonprofit that promised help and delivered betrayal.

Her defense mechanism: Invisibility. Don't ask for help. Don't leave traces. Don't exist in systems.

Her want: Housing. Work. Basic survival.
Her need: To be human, not illegal. To seek help without risking everything.

*[Pause. Let these people become real.]*

Five groups. Five sets of ghosts and wounds and dreams.
One principle: AI serves the humans. Humans govern the AI. Always."

**発表者ノート（日本語）:**

「私たちは一つの模合を構築しているのではありません。五つ構築しています。脆弱性は一枚岩ではありません—断片化され、交差的で、具体的だからです。

*[各ペルソナのために声を変える—それらを区別する]*

**信頼模合。**
ハルトのような人々のため。74歳。未亡人。まだ妻の香水の匂いがするアパートで一人暮らし。彼が抱える幽霊：時代遅れ。彼はかつて役に立った—帳簿のバランスを取り、家族を支え、重要だった。今は？パートタイムの仕事を失った。別の都市の子供たち。一人で死ぬことが老化の代償であるという恐怖。

彼の欲求：安全。医療緊急事態への対処。詐欺の回避。
彼のニーズ：まだ重要であること。まだ何かの一部であること。見られること。

**未来模合。**
ダイチのような人々のため。28歳。脳性麻痺。車椅子使用者。従わない体に閉じ込められた輝く心。

彼が抱える幽霊：負担。彼が不便であり、アクセシビリティは彼が所有する権利ではなく人々が与える好意であると言う声。

彼の欲求：コミュニティイベントに参加すること。完全に参加すること。含まれること。
彼のニーズ：後付けで対応されるのではなく、設計されること。彼の専門知識が認識されること。

**希望模合。**
ユイのような人々のため。22歳。彼女の部屋：六畳。ドア：2年間閉じられている。窓：覆われている。世界：うるさすぎる、明るすぎる、多すぎる。

彼女が抱える幽霊：判断。もし彼女が外に出たら、みんなが彼女がどれだけ壊れているかを見るという確信。

彼女の防衛機制：引きこもり。失敗できなければ、傷つくことはできない。

彼女の欲求：こんなに孤独を感じるのをやめること。
彼女のニーズ：癒しが直線的ではないこと、参加が完璧を必要としないこと、彼女が壊れているのではなく、ただ傷ついているだけであることを学ぶこと。

**唯一模合。**
サクラのような人々のため。31歳。移行して7年。彼女の本当の自分がついに見える—そしてそれゆえに脆弱。

彼女が抱える幽霊：暴露。データベース侵害。検索結果で彼女の法的名前に永遠に付けられた旧名。それに続いた暴力。

彼女の防衛機制：過度の警戒。システムを信頼しない。すべてを暗号化する。必要に応じて消える。

彼女の欲求：差別と暴力からの安全。
彼女のニーズ：隠れずに存在すること。危険にさらされずに見られること。

**自由模合。**
ソラのような人々のため。25歳。非正規滞在。二つの仕事。13時間の日々。実家に送られるお金。ビザ期限切れ。

彼女が抱える幽霊：彼女の友人マリア。国外退去。里親養育の子供たち。助けを約束し裏切りを提供した非営利団体。

彼女の防衛機制：不可視性。助けを求めない。痕跡を残さない。システムに存在しない。

彼女の欲求：住宅。仕事。基本的な生存。
彼女のニーズ：違法ではなく人間であること。すべてを危険にさらさずに助けを求めること。

*[間を取る。これらの人々を現実にする。]*

5つのグループ。5つの幽霊と傷と夢のセット。
一つの原則：AIは人間に奉仕します。人間がAIを管理します。常に。」

---

## Slide 8: User Journey - Yui's Transformation

**Speaker Notes (English):**

"Let me tell you what healing looks like when you design with patience instead of metrics.

**Month 0:**
Yui's mother sits at her kitchen table, tea gone cold, phone in hand. She's scrolling through mental health resources with the desperation of someone who's tried everything. Two years. Her daughter hasn't opened that door in two years except to take the food trays left outside.

She finds Kibou MOAI through a forum for parents of hikikomori. The word itself carries shame in Japan—social withdrawal, failure to launch, a child who can't face the world. But the forum is anonymous, and desperation makes you honest.

**Month 1:**
First contact. Not a phone call—Yui would never answer. Not a knock on the door—that would send her deeper into her room. A text message. Simple. One sentence:

'Hi. I'm Aya from Kibou MOAI. I'm here when you're ready. No pressure. No timeline. Just here.'

Yui reads it. Her heart rate spikes—that familiar adrenaline that comes with any human contact. She doesn't respond. The message doesn't send a read receipt. The AI knows better.

**Month 2:**
Another message. A photo this time. A cat café the other members visited. Five people holding cats. Smiling. The caption: 'Tried to count all the cats. Lost track at seventeen.'

No obligation to comment. No 'You should come next time!' No pressure disguised as invitation.

Yui looks at the photo. She likes cats. She had a cat once, before... before the door closed. She saves the image.

**Month 4:**
Yui sends her first message. One word: 'Cute.'

For anyone else, it's nothing. For Yui, it's a crack in the wall.

The group responds, but the AI has calibrated them. No overwhelming enthusiasm. No 'SO GLAD YOU'RE HERE!!!' that would make her feel like a project, like someone to fix.

Just: 'Right? The orange one tried to steal my tea.'

Yui's mother cries in the kitchen. Her daughter spoke. To strangers. By choice.

**Month 6:**
Online voice chat. Camera off. Yui's voice is small, rusty from disuse. She mostly just listens. Hears Kenji talk about his panic attacks. Hears Aya describe the weight of leaving her apartment—how she has to plan routes with escape paths, how crowded trains feel like drowning.

For the first time in two years, Yui doesn't feel alone. Doesn't feel like the only one who can't do basic things everyone else does without thinking.

**Month 8:**
The first in-person meeting. The AI suggests it, but the humans plan it:
- Quiet café, not crowded
- One hour maximum, timer set
- Aya will be there—another anxious person who gets it
- Exit strategy prepared: 'If you need to leave, just say you forgot something. No explanations needed.'

Yui stands outside her door for eleven minutes. Her hand on the knob. The door feels like it weighs a thousand kilograms.

She opens it.

The café is exactly what they promised. Quiet. Soft lighting. Aya is in the corner, wearing a yellow cardigan like she said she would. She waves, gentle, not excited.

Yui stays forty-five minutes. It's exhausting. It's terrifying. It's progress.

She goes home and sleeps for fourteen hours.

**Month 12:**
Yui volunteers to design event posters remotely. She mentions, almost shy, that she studied graphic design before... before.

The posters are beautiful. Minimalist. Clever. The group loves them.

Someone says: 'You're really talented.'

Yui types: 'Thank you.'

And means it.

*[Pause. Voice soft but strong.]*

The AI made this possible not by pushing, but by understanding. Healing isn't linear. Support means meeting people where they are. Technology should adapt to humans, not demand humans adapt to it.

Yui still has hard days. The door still feels heavy sometimes. But she's not alone anymore. And that changes everything."

**発表者ノート（日本語）:**

「メトリクスではなく忍耐で設計したときに癒しがどのように見えるかお話しさせてください。

**0ヶ月目:**
ユイの母親はキッチンテーブルに座り、お茶は冷め、電話を手に。彼女はすべてを試した人の絶望でメンタルヘルスリソースをスクロールしています。2年。娘は2年間、外に残された食べ物のトレイを取る以外、あのドアを開けていません。

彼女はひきこもりの親のフォーラムを通じて希望模合を見つけます。言葉自体が日本で恥を運びます—社会的引きこもり、打ち上げの失敗、世界に直面できない子供。しかしフォーラムは匿名で、絶望はあなたを正直にします。

**1ヶ月目:**
最初の接触。電話ではありません—ユイは決して答えません。ドアのノックではありません—それは彼女をより深く部屋に送ります。テキストメッセージ。シンプル。一文：

「こんにちは。希望模合のアヤです。準備ができたらここにいます。プレッシャーなし。タイムラインなし。ただここに。」

ユイはそれを読みます。彼女の心拍数が急上昇します—どんな人間接触でも来る馴染みのあるアドレナリン。彼女は返信しません。メッセージは既読通知を送りません。AIはより良く知っています。

**2ヶ月目:**
別のメッセージ。今回は写真。他のメンバーが訪れた猫カフェ。猫を抱いた5人。笑顔。キャプション：「すべての猫を数えようとしました。17で追跡を失いました。」

コメントする義務なし。「次回は来てください！」なし。招待に偽装されたプレッシャーなし。

ユイは写真を見ます。彼女は猫が好きです。彼女はかつて猫を飼っていました、...ドアが閉まる前。彼女は画像を保存します。

**4ヶ月目:**
ユイが最初のメッセージを送ります。一言：「かわいい。」

他の誰にとっても、それは何でもありません。ユイにとって、それは壁のひび割れです。

グループは応答しますが、AIは彼らを較正しました。圧倒的な熱意なし。「あなたがここにいてとてもうれしい！！！」なし。それは彼女をプロジェクトのように、修正する誰かのように感じさせます。

ただ：「でしょう？オレンジ色のやつが私のお茶を盗もうとしました。」

ユイの母親はキッチンで泣きます。娘が話しました。見知らぬ人に。選択によって。

**6ヶ月目:**
オンライン音声チャット。カメラオフ。ユイの声は小さく、使わないことで錆びています。彼女は主に聞くだけ。賢二がパニック発作について話すのを聞きます。アヤがアパートを出ることの重みを説明するのを聞きます—どのように脱出経路のあるルートを計画しなければならないか、混雑した電車がどのように溺れるように感じるか。

2年ぶりに、ユイは一人ではないと感じます。他のみんなが考えずにする基本的なことができない唯一の人ではないと感じます。

**8ヶ月目:**
最初の対面ミーティング。AIはそれを提案しますが、人間がそれを計画します：
- 静かなカフェ、混雑していない
- 最大1時間、タイマーセット
- アヤがそこにいる—理解する別の不安な人
- 退出戦略準備済み：「出る必要がある場合、何かを忘れたと言ってください。説明は必要ありません。」

ユイはドアの外に11分間立っています。ノブに手を置いて。ドアは1000キログラムの重さのように感じます。

彼女はそれを開けます。

カフェは彼らが約束した通りです。静か。柔らかい照明。アヤは隅にいて、彼女が言った通り黄色いカーディガンを着ています。彼女は手を振ります、穏やかに、興奮していません。

ユイは45分滞在します。疲れます。恐ろしいです。進歩です。

彼女は家に帰り、14時間眠ります。

**12ヶ月目:**
ユイはリモートでイベントポスターをデザインすることを志願します。彼女は、ほとんど恥ずかしそうに、...その前にグラフィックデザインを勉強していたと言います。

ポスターは美しいです。ミニマリスト。賢い。グループはそれらが大好きです。

誰かが言います：「あなたは本当に才能があります。」

ユイはタイプします：「ありがとうございます。」

そして本気です。

*[間を取る。声は柔らかいが強い。]*

AIはこれを可能にしました。押すことによってではなく、理解することによって。癒しは直線的ではありません。サポートは人々がいる場所で会うことを意味します。技術は人間に適応すべきであり、人間が技術に適応することを要求すべきではありません。

ユイにはまだ難しい日があります。ドアはまだ時々重く感じます。しかし彼女はもう一人ではありません。そしてそれがすべてを変えます。」

---

## Slide 9: Storyboard - The Night Haruto Survived

**Speaker Notes (English):**

"Let me take you back to that night. Panel by panel. Second by second.

**Panel 1: 11:47 PM**
Haruto's kitchen. The overhead light flickers slightly—needs replacing, but he keeps forgetting. The termination letter is on the table, white paper against cheap wood grain, the corporate letterhead like an accusation. The ramen bowl, contents congealed into a cold, unappetizing mass. And Haruto's face—fear, yes, but more than that. The peculiar shame of needing help.

His chest: the spreading pressure. Like a fist closing slowly around his heart.

**Panel 2: The Button**
His phone screen glows in his hand. The interface: simple, large, clear. One button. Red. The color of emergency, universal across cultures.

He taps it.

His finger shakes. But the button is large enough. The interface forgiving enough. The design doesn't punish trembling hands.

**Panel 3: 2 Seconds - Behind the Scenes**
*[This is where you make them see the invisible architecture]*

The AI pulls his medical file from local encrypted storage. Not from the cloud—from his device. Instant. Private.

Atrial fibrillation. Warfarin for blood thinning. Penicillin allergy—life-threatening. The stent placed in 2022 in his left anterior descending artery.

Four phones light up simultaneously. The emergency alert: formatted, prioritized, clear. Not 'Haruto pushed a button.' But 'Suspected cardiac event. Patient conscious. Medical history attached. Ambulance dispatched.'

Emergency services receive the alert with location coordinates accurate to three meters and pre-filled medical data that would normally take ten minutes of questioning to gather.

**Panel 4: Keiko Runs**
She's in her nightgown. Floral pattern, faded from washing. Reading glasses still on. She doesn't grab a coat. Doesn't change. Doesn't hesitate.

The other three MOAI members join a video call. Their faces on Haruto's screen. Not silent observers—family. Talking to him. Keeping him conscious. Keeping him calm.

'Breathe, Haruto-san. Slow. The ambulance is coming.'
'We're here. You're not alone.'

He's not alone.

**Panel 5: 5 Minutes - The Paramedics Arrive**
Sirens carving through the Tokyo night. Red lights reflecting off rain-slicked streets.

Keiko meets them at the building entrance. She's holding the tablet—the AI prepared it. Haruto's complete medical history displayed in the format paramedics actually use, not a PDF they'd have to scroll through while a man dies.

They don't waste thirty seconds asking 'Any allergies?' They already know: Penicillin.
They don't waste time asking 'Current medications?' They already know: Warfarin.
They don't fumble for his address, his emergency contact, his medical ID number.

They just work. Fast. Competent. Informed.

**Panel 6: Two Days Later - Recovery**
Haruto in a hospital bed. Not alone. The MOAI has coordinated visits—someone every day. Takeshi brought flowers. Yumiko brought magazines. Hiroshi brought terrible jokes.

The emergency fund covered the ambulance. The legal entity is handling insurance paperwork—the bureaucracy that drowns vulnerable elderly people in confusion.

And meals. Pre-cooked, delivered to his apartment, ready for when he comes home. Because the MOAI knows that recovery includes the small things—the things that make you feel human, cared for, worth the trouble.

*[Pause. Make eye contact.]*

This is what 0.16 milliseconds of latency means when translated into human terms.
This is what privacy-preserving architecture enables when it's not theoretical.
This is what happens when AI augments human community instead of attempting to replace it.

Haruto survived that night. Not because of the technology alone. Because Keiko cared enough to run. The AI just made that caring effective enough to save a life."

**発表者ノート（日本語）:**

「あの夜に戻りましょう。パネルごとに。秒ごとに。

**パネル1：午後11時47分**
ハルトのキッチン。天井の照明がわずかにちらつきます—交換が必要ですが、彼は忘れ続けています。解雇通知はテーブルの上、安っぽい木目に対する白い紙、告発のような企業のレターヘッド。ラーメンボウル、内容物は冷たく食欲をそそらない塊に凝固。そしてハルトの顔—恐怖、はい、しかしそれ以上。助けを必要とすることの独特の恥。

彼の胸：広がる圧力。彼の心臓の周りでゆっくりと閉じる拳のように。

**パネル2：ボタン**
彼の電話画面が彼の手で光ります。インターフェース：シンプル、大きい、明確。一つのボタン。赤。緊急の色、文化を超えて普遍的。

彼はそれをタップします。

彼の指は震えます。しかしボタンは十分大きい。インターフェースは十分に寛容。デザインは震える手を罰しません。

**パネル3：2秒 - 舞台裏**
*[ここで彼らに見えないアーキテクチャを見せる]*

AIはローカル暗号化ストレージから彼の医療ファイルを引き出します。クラウドからではなく—彼のデバイスから。即座。プライベート。

心房細動。血液希釈のためのワーファリン。ペニシリンアレルギー—生命を脅かす。2022年に左前下行動脈に配置されたステント。

4つの電話が同時に光ります。緊急アラート：フォーマットされ、優先順位付けられ、明確。「ハルトがボタンを押しました」ではありません。しかし「心臓イベントの疑い。患者意識あり。病歴添付。救急車派遣済み。」

緊急サービスは3メートルまで正確な位置座標と、通常収集するのに10分の質問を要する事前入力された医療データでアラートを受け取ります。

**パネル4：恵子が走る**
彼女はナイトガウン姿。花柄、洗濯で色褪せている。老眼鏡はまだかけている。彼女はコートを取りません。着替えません。ためらいません。

他の3人の模合メンバーがビデオ通話に参加します。ハルトの画面上の彼らの顔。沈黙の観察者ではありません—家族。彼に話しかけています。彼を意識させ続けています。彼を落ち着かせています。

「ハルトさん、呼吸してください。ゆっくり。救急車が来ています。」
「私たちはここにいます。あなたは一人ではありません。」

彼は一人ではありません。

**パネル5：5分 - 救急隊員が到着**
東京の夜を切り裂くサイレン。雨に濡れた通りに反射する赤い光。

恵子は建物の入り口で彼らに会います。彼女はタブレットを持っています—AIがそれを準備しました。救急隊員が実際に使用する形式で表示されたハルトの完全な病歴、男性が死ぬ間にスクロールしなければならないPDFではありません。

彼らは「アレルギーはありますか？」と尋ねる30秒を無駄にしません。彼らはすでに知っています：ペニシリン。
彼らは「現在の薬は？」と尋ねる時間を無駄にしません。彼らはすでに知っています：ワーファリン。
彼らは彼の住所、緊急連絡先、医療ID番号をもたつきません。

彼らはただ働きます。速く。有能。情報を得て。

**パネル6：2日後 - 回復**
病院のベッドのハルト。一人ではありません。模合は訪問を調整しました—毎日誰か。武さんは花を持ってきました。由美子さんは雑誌を持ってきました。宏さんはひどい冗談を持ってきました。

緊急基金が救急車をカバーしました。法人が保険の書類を処理しています—脆弱な高齢者を混乱で溺れさせる官僚制。

そして食事。調理済み、彼のアパートに配達され、彼が家に帰ったときの準備完了。なぜなら模合は回復が小さなことを含むことを知っているからです—あなたを人間らしく、世話され、手間をかける価値があると感じさせるもの。

*[間を取る。アイコンタクト。]*

これが人間の言葉に翻訳されたときの0.16ミリ秒のレイテンシが意味することです。
これが理論的ではないときにプライバシー保護アーキテクチャが可能にすることです。
これがAIが人間のコミュニティを置き換えようとするのではなく強化したときに起こることです。

ハルトはその夜生き延びました。技術だけのためではありません。恵子さんが走るほど気にかけたからです。AIはその思いやりを命を救うのに十分効果的にしただけです。」

---

## Slide 10: The Technology - How It Actually Works

**Speaker Notes (English):**

"I know what you're thinking. This sounds too good. Where's the catch? What's the hidden cost?

*[Pause. Firm voice.]*

There's no catch. But there is sophisticated technology making this possible. Let me show you the engine under the hood.

The platform: AIngle DLT. We built it originally for the EU H2020 FASTER project—first responder emergency communication. Police, fire, paramedics. When seconds decide whether someone lives or dies. When privacy breaches can endanger witnesses, victims, undercover agents. When failure isn't an option because lives are literally on the line.

That origin shaped everything.

**Local-first architecture:**
Your data lives on your device. Not metaphorically—literally. Your messages, your medical records, your location history—they exist on hardware you control.

When you sync with your MOAI members, it's peer-to-peer, device to device, encrypted with quantum-resistant algorithms. No stop in California. No detour through Tokyo. No server that can be breached, subpoenaed, sold to the highest bidder.

If the company building this goes bankrupt tomorrow, your MOAI keeps working. Because the infrastructure is distributed, federated, resilient.

**Semantic knowledge layer:**
This is what enables cultural awareness. We use RDF and OWL ontologies—semantic web technologies that understand relationships, context, meaning.

The AI doesn't just translate 'formal Japanese' to 'polite mode.' It understands that Haruto's preference for formal speech reflects his generation, his education, his values. It knows that switching to casual speech would feel like disrespect, not friendliness.

It doesn't just convert to 'Easy Japanese.' It understands that Easy Japanese is a framework developed for non-native speakers, people with cognitive disabilities, older adults learning new technology. It adjusts vocabulary, sentence structure, information density—not condescending, but clarifying.

**Performance benchmarks:**
We've tested this rigorously. Over 2 million operations. Real-world load testing.

Average latency for semantic queries: 0.16 milliseconds. That's faster than human perception. That's the difference between Keiko getting the alert while Haruto is still conscious versus getting it too late.

Peak throughput: over 7,000 transactions per second. That's not theoretical—that's measured performance under stress testing.

Reliability: 100% across all test scenarios. Because 99.9% reliability means one in a thousand emergencies fails. And that one could be Haruto.

**Offline-first operation:**
When the internet goes down—during disasters, in rural areas, in the situations where vulnerable people need help most—Digital MOAI keeps working.

Local storage. Local computation. Eventual consistency when connectivity returns.

Because in a disaster, the most vulnerable are often in the places with the worst connectivity. And we refuse to build a system that abandons them when they need us most.

*[Pause. Let this sink in.]*

This isn't vaporware. This isn't a prototype that works in demos and fails in reality. This is production-grade infrastructure tested under conditions where failure costs lives.

The technology is sophisticated. The architecture is robust. The performance is verified.

But the technology isn't the point. The technology serves the humans. Always."

**発表者ノート（日本語）:**

「皆さんが考えていることは分かります。これはあまりにも良すぎる。裏は？隠されたコストは？

*[間を取る。しっかりとした声。]*

裏はありません。しかしこれを可能にする洗練された技術があります。フードの下のエンジンをお見せしましょう。

プラットフォーム：AIngle DLT。私たちは元々EU H2020 FASTERプロジェクト—初動対応者の緊急通信のためにこれを構築しました。警察、消防、救急隊員。秒が誰かが生きるか死ぬかを決定するとき。プライバシー侵害が証人、被害者、潜入捜査官を危険にさらす可能性があるとき。失敗が選択肢ではないとき、なぜなら命が文字通り危機にさらされているからです。

その起源がすべてを形作りました。

**ローカルファーストアーキテクチャ:**
データはあなたのデバイスに保存されます。比喩的にではなく—文字通り。あなたのメッセージ、医療記録、位置履歴—それらはあなたが制御するハードウェアに存在します。

模合メンバーと同期するとき、ピアツーピア、デバイスからデバイスへ、量子耐性アルゴリズムで暗号化されます。カリフォルニアでの停止なし。東京を経由する迂回なし。侵害され、召喚状を受け、最高入札者に売られることができるサーバーなし。

これを構築している会社が明日破産しても、あなたの模合は動作し続けます。なぜならインフラストラクチャは分散され、連合され、回復力があるからです。

**セマンティック知識レイヤー:**
これが文化的認識を可能にするものです。私たちはRDFとOWLオントロジーを使用します—関係、文脈、意味を理解するセマンティックウェブ技術。

AIは単に「丁寧な日本語」を「礼儀モード」に翻訳しません。ハルトの丁寧な話し方への好みが彼の世代、教育、価値観を反映していることを理解します。カジュアルな話し方に切り替えることが友好的ではなく無礼に感じることを知っています。

それは単に「やさしい日本語」に変換しません。やさしい日本語が非母語話者、認知障害を持つ人々、新しい技術を学ぶ高齢者のために開発されたフレームワークであることを理解します。語彙、文構造、情報密度を調整します—見下すのではなく、明確化します。

**パフォーマンスベンチマーク:**
私たちはこれを厳密にテストしました。200万以上の操作。実世界の負荷テスト。

セマンティッククエリの平均レイテンシ：0.16ミリ秒。それは人間の知覚より速い。それは恵子さんがハルトがまだ意識があるときにアラートを取得するか、遅すぎるときに取得するかの違いです。

ピークスループット：毎秒7,000トランザクション以上。それは理論ではありません—ストレステスト下で測定されたパフォーマンスです。

信頼性：すべてのテストシナリオで100%。なぜなら99.9%の信頼性は1000の緊急事態のうち1つが失敗することを意味するからです。そしてその1つがハルトである可能性があります。

**オフラインファースト操作:**
インターネットがダウンしたとき—災害時、農村地域、脆弱な人々が最も助けを必要とする状況で—デジタル模合は動作し続けます。

ローカルストレージ。ローカル計算。接続が戻ったときの最終的一貫性。

なぜなら災害時、最も脆弱な人々はしばしば最悪の接続性のある場所にいるからです。そして私たちは彼らが私たちを最も必要とするときに彼らを見捨てるシステムを構築することを拒否します。

*[間を取る。これを沈める。]*

これはベーパーウェアではありません。デモで動作し現実で失敗するプロトタイプではありません。これは失敗が命を犠牲にする条件下でテストされた本番グレードのインフラストラクチャです。

技術は洗練されています。アーキテクチャは堅牢です。パフォーマンスは検証されています。

しかし技術はポイントではありません。技術は人間に奉仕します。常に。」

---

## Slide 11: Four Principles - Our North Star

**Speaker Notes (English):**

"Building this taught us that principles matter more than features. We could add a thousand capabilities and still fail the people we're trying to serve if we violate these four principles.

Let me tell you how we learned each one—through failure.

**Principle 1: Human Primacy**

Our early prototype gave the AI more autonomy. We thought we were being helpful. If someone missed medication twice, the AI would automatically notify their MOAI members. Proactive! Caring!

Users hated it. Rightfully.

One tester—an elderly man with diabetes—said something that haunts me: 'I felt like a child being tattled on.'

We had violated his agency. Made him feel watched, controlled, infantilized. We had prioritized efficiency over dignity.

We learned: AI suggests. Humans decide. Always. No exceptions. Every single time.

**Principle 2: Accessibility First**

We designed the initial interface like every other app. Clean. Modern. Standard touch targets. Standard navigation.

Then we met Daichi.

He looked at our beautiful interface and said, flatly: 'I can't use this.'

We could have added 'accessibility features'—made the buttons bigger, added voice control as an option. That's what most companies do. Retrofit. Accommodate. Check the compliance box.

Instead, we said: 'Teach us how to build this right.'

Daichi became our lead accessibility consultant. Not because we felt sorry for him. Because he's the expert. He knows what works. He knows what fails in ways we—able-bodied designers—never would.

Voice-first became the primary input method. Not mouse-first with voice backup. Voice-first.

And then something beautiful happened. Older users preferred Daichi's interface. People with temporary disabilities loved it. Non-native speakers found it more approachable.

When you design for the edges, you improve the center. Every time.

**Principle 3: Privacy Sovereignty**

We tried working with existing identity management systems. Convenient. Standard. Interoperable.

Then we talked to Sora. And Sakura. And understood: for them, using any centralized identity system is existential risk.

One data breach. One subpoena. One government request. And Sora is deported. Sakura is outed. Maria loses her children.

This isn't about GDPR compliance. This isn't about following best practices. This is about understanding that for vulnerable populations, privacy isn't a feature you add—it's the foundation without which nothing else matters.

Local-first architecture isn't a technical choice. It's a moral choice.

**Principle 4: Cultural Context-Awareness**

We tried machine translation first. Google Translate API. Fast. Cheap. Good enough, we thought.

It failed spectacularly.

The AI would switch Haruto to casual Japanese to 'sound friendlier.' He felt disrespected.
It would translate 'Easy Japanese' to 'simplified language,' missing that it's a whole framework with specific design principles.
It would miss cultural context that changes meaning—the difference between 'no' and 'no (but actually yes to be polite).'

We learned: translation isn't enough. You need understanding. Not just words—worlds.

Semantic ontologies that capture relationships, context, cultural nuance. Built in from day one. Not retrofitted.

*[Pause. Voice firm.]*

These aren't aspirational goals. They're hard requirements. Violate them and we don't just build a worse product—we build a weapon that harms the people we're trying to help.

We learned these principles through failure. Through listening. Through humility.

They're our north star. Non-negotiable."

**発表者ノート（日本語）:**

「これを構築することで、原則が機能よりも重要であることを学びました。私たちは千の機能を追加できますが、これらの4つの原則に違反すれば、私たちが奉仕しようとしている人々を失望させます。

それぞれを失敗を通じてどのように学んだかお話しさせてください。

**原則1：人間の優位性**

初期のプロトタイプはAIにより多くの自律性を与えました。私たちは役に立つと思っていました。誰かが薬を2回逃した場合、AIは自動的に模合メンバーに通知します。積極的！思いやり！

ユーザーはそれを嫌いました。当然です。

あるテスター—糖尿病の高齢男性—は私を悩ませる何かを言いました：「告げ口される子供のように感じました。」

私たちは彼の主体性を侵害しました。彼を監視され、制御され、幼稚に扱われていると感じさせました。私たちは尊厳より効率性を優先しました。

私たちは学びました：AIは提案します。人間が決定します。常に。例外なし。毎回。

**原則2：アクセシビリティファースト**

私たちは他のすべてのアプリのように初期インターフェースを設計しました。クリーン。モダン。標準的なタッチターゲット。標準的なナビゲーション。

それから私たちはダイチに会いました。

彼は私たちの美しいインターフェースを見て、きっぱりと言いました：「これは使えません。」

私たちは「アクセシビリティ機能」を追加することもできました—ボタンを大きくし、オプションとして音声制御を追加。それはほとんどの会社がすることです。後付け。対応。コンプライアンスボックスをチェック。

代わりに、私たちは言いました：「これを正しく構築する方法を教えてください。」

ダイチは私たちの主任アクセシビリティコンサルタントになりました。私たちが彼を気の毒に思ったからではありません。彼が専門家だからです。彼は何が機能するかを知っています。私たち—健常者のデザイナー—が決して知らない方法で何が失敗するかを知っています。

音声ファーストが主要な入力方法になりました。バックアップとして音声を持つマウスファーストではありません。音声ファースト。

そして美しいことが起こりました。高齢ユーザーがダイチのインターフェースを好みました。一時的な障害を持つ人々がそれを愛しました。非母語話者はそれをよりアプローチしやすいと感じました。

エッジのために設計するとき、センターを改善します。毎回。

**原則3：プライバシー主権**

私たちは既存のアイデンティティ管理システムとの作業を試みました。便利。標準。相互運用可能。

それから私たちはソラと話しました。そしてサクラと。そして理解しました：彼らにとって、中央集権型のアイデンティティシステムを使用することは存続リスクです。

一つのデータ漏洩。一つの召喚状。一つの政府の要求。そしてソラは国外退去。サクラはカミングアウト。マリアは子供を失います。

これはGDPRコンプライアンスについてではありません。ベストプラクティスに従うことについてではありません。これは、脆弱な人々にとって、プライバシーが追加する機能ではなく、それなしでは他のすべてが重要でない基盤であることを理解することについてです。

ローカルファーストアーキテクチャは技術的選択ではありません。道徳的選択です。

**原則4：文化的文脈認識**

私たちは最初に機械翻訳を試しました。Google Translate API。速い。安い。十分だと思いました。

それは見事に失敗しました。

AIはハルトをカジュアルな日本語に切り替えて「よりフレンドリーに聞こえる」ようにします。彼は無礼に感じました。
それは「やさしい日本語」を「簡略化された言語」に翻訳し、それが特定の設計原則を持つ全体的なフレームワークであることを見逃します。
それは意味を変える文化的文脈を見逃します—「いいえ」と「いいえ（しかし実際には礼儀正しくするためにはい）」の違い。

私たちは学びました：翻訳では不十分です。理解が必要です。言葉だけでなく—世界。

関係、文脈、文化的ニュアンスを捕捉するセマンティックオントロジー。初日から構築。後付けではなく。

*[間を取る。声をしっかりと。]*

これらは願望的な目標ではありません。厳しい要件です。それらに違反すると、私たちは単に悪い製品を構築するだけでなく、私たちが助けようとしている人々を傷つける武器を構築します。

私たちはこれらの原則を失敗を通じて学びました。聞くことを通じて。謙虚さを通じて。

それらは私たちの北極星です。譲れません。」

---

## Slide 12: Trust Calibration - Respecting Agency

**Speaker Notes (English):**

"Let me tell you about the moment we violated Haruto's dignity. The moment we learned that good intentions pave roads to terrible places.

Early version. Month two of testing. Haruto missed his evening medication twice in one week. The AI, helpful and proactive, sent an alert to his MOAI members: 'Haruto has missed medication twice. Please check on him.'

Keiko called him. Concerned. Caring. 'Haruto-san, are you okay? Your medication...'

*[Pause. Lower voice.]*

He hung up on her. First time in three years of friendship.

When we asked why, his voice was quiet but firm: 'I forgot. I'm seventy-four. Sometimes I forget. But I don't need to be treated like a child who can't be trusted with his own pills.'

We had optimized for safety. We had destroyed dignity.

*[Voice shifts—teaching mode]*

Trust isn't binary—on or off, safe or unsafe. Trust is calibrated. It evolves. It requires consent at every level.

**Level 1: Suggestion Only** —The default. Always the starting point.

The AI notices: 'I see you haven't taken your evening medication. Would you like a reminder?'

And then it waits. It shows its reasoning: 'You usually take warfarin at 8 PM. It's now 9:30 PM.' Transparent. Not demanding. Respectful.

Haruto can say yes. Can say no. Can say 'stop reminding me about this entirely.' His choice. His agency. His life.

**Level 2: Automatic with Notification**—After trust has been built. After the human decides.

The AI takes routine actions—scheduling the Tuesday meeting, adjusting the emergency fund calculations—but immediately tells you what it did. Twenty-four-hour undo window. Full transparency.

Like having an assistant who acts but keeps you informed. Who serves but doesn't supplant.

**Level 3: Automatic with Escalation**—For experienced users. For well-calibrated trust.

The AI handles routine tasks independently. But it knows—through machine learning on individual patterns—the difference between routine and unusual.

'Haruto's regular Tuesday meeting' → Handle it.
'Haruto hasn't responded to check-ins for three days' → Escalate to humans immediately.

The AI doesn't decide what's unusual. The MOAI members do, through collective configuration of escalation rules.

*[Pause. Make this land.]*

And critically—unchangeably—all five MOAI members must agree on automation policies.

Haruto can't opt Keiko into Level 3 automation without her consent. Keiko can't force the group to adopt features she prefers. One person, one vote. Democracy at the scale where democracy actually functions.

Trust isn't given. It's earned. Slowly. With transparency. With the constant option to revoke.

We learned this by failing Haruto. By making him feel infantilized instead of supported. By confusing efficiency with care.

We won't make that mistake again."

**発表者ノート（日本語）:**

「ハルトの尊厳を侵害した瞬間についてお話しさせてください。善意が恐ろしい場所への道を舗装することを学んだ瞬間。

初期バージョン。テストの2ヶ月目。ハルトは1週間に2回夕方の薬を逃しました。AIは、親切で積極的に、模合メンバーにアラートを送りました：「ハルトが2回薬を逃しました。彼をチェックしてください。」

恵子さんは彼に電話しました。心配して。思いやって。「ハルトさん、大丈夫ですか？あなたの薬...」

*[間を取る。声を下げる。]*

彼は彼女に電話を切りました。3年間の友情で初めて。

なぜか尋ねたとき、彼の声は静かだがしっかりしていました：「忘れました。私は74歳です。時々忘れます。しかし自分の薬を信頼できない子供のように扱われる必要はありません。」

私たちは安全性のために最適化しました。私たちは尊厳を破壊しました。

*[声を変える—教えるモード]*

信頼は二値ではありません—オンかオフ、安全か不安全か。信頼は較正されます。進化します。すべてのレベルで同意を必要とします。

**レベル1：提案のみ** —デフォルト。常に出発点。

AIは気づきます：「夕方の薬を服用していないようです。リマインダーが必要ですか？」

そして待ちます。推論を示します：「通常午後8時にワーファリンを服用します。今は午後9時30分です。」透明。要求しない。尊重する。

ハルトははいと言えます。いいえと言えます。「これについて完全にリマインドするのをやめて」と言えます。彼の選択。彼の主体性。彼の人生。

**レベル2：通知付き自動**—信頼が構築された後。人間が決定した後。

AIは定型アクションを実行します—火曜日の会議のスケジューリング、緊急基金の計算の調整—しかし何をしたかをすぐに伝えます。24時間の取り消しウィンドウ。完全な透明性。

行動するが情報を提供するアシスタントを持っているようなものです。奉仕するが置き換えない。

**レベル3：エスカレーション付き自動**—経験豊富なユーザーのため。よく較正された信頼のため。

AIは定型タスクを独立して処理します。しかし、個々のパターンでの機械学習を通じて、定型と異常の違いを知っています。

「ハルトの定期的な火曜日の会議」→処理する。
「ハルトが3日間チェックインに応答していない」→すぐに人間にエスカレート。

AIは何が異常かを決定しません。模合メンバーが、エスカレーションルールの集団的設定を通じて決定します。

*[間を取る。これを着地させる。]*

そして重要なこと—変更不可能に—すべての5人の模合メンバーが自動化ポリシーに同意する必要があります。

ハルトは恵子さんの同意なしに彼女をレベル3自動化に参加させることはできません。恵子さんは彼女が好む機能を採用するようグループを強制できません。一人、一票。民主主義が実際に機能するスケールでの民主主義。

信頼は与えられません。獲得されます。ゆっくりと。透明性を持って。常に取り消すオプションを持って。

私たちはハルトを失望させることによってこれを学びました。彼をサポートされるのではなく幼稚に扱われていると感じさせることによって。効率性とケアを混同することによって。

私たちはその間違いを二度としません。」

---

## Slide 13: Accessibility - Designed Together

**Speaker Notes (English):**

"I want you to meet Daichi. Really meet him. Not as a case study. As a person who taught us everything we know about designing interfaces that serve instead of exclude.

Twenty-eight years old. Cerebral palsy since birth. His mind is sharp enough to code in three programming languages, sharp enough to finish university with honors, sharp enough to see through our well-intentioned bullshit in about thirty seconds.

His hands don't obey him. The tremor is constant. Fine motor control—the kind required to tap a small button on a screen—is impossible some days, exhausting on good days.

*[Shift tone—become Daichi's voice, if you can]*

First meeting. We showed him our prototype. Proud. 'Look what we built for people like you.'

He looked at the screen. Looked at us. Said, flatly: 'I can't use this. And I'm not 'people like me.' I'm Daichi.'

*[Back to your voice—humbled]*

We could have said: 'Okay, we'll make the buttons bigger. Add voice control as an option. Check the accessibility compliance box.'

That's what most companies do. Retrofit. Accommodate. Treat accessibility as a problem to solve rather than a perspective to learn from.

We said something different: 'Teach us. Show us how to build this right.'

Daichi became our lead accessibility consultant. Not as charity. Not because we pitied him. Because he's the expert on interfaces for people whose bodies don't match the assumptions of able-bodied designers.

He's paid. Properly. At consultant rates. Because expertise has value.

*[Demonstrate with your hands if possible—show the gestures]*

**Voice-first became the primary input method.**

Not 'click here and optionally use voice.' Voice-first. The fundamental interaction model. Mouse and touch as alternatives, not primaries.

'Mamoru, when is the next meeting?'
'Mamoru, message Keiko: I'll be ten minutes late.'
'Mamoru, read my notifications.'

Simple. Natural. Fast.

**Gesture simplification.**

Not 'make the buttons bigger.' Eliminate precision requirements entirely.

Large touch targets—yes. But also: swipe instead of tap. Shake to undo. Tilt to scroll. Movement that doesn't require hitting a specific pixel on a screen.

**High-contrast modes.**

Not 'dark mode and light mode.' Twelve different color combinations tested with users who have different types of visual impairment. Let them choose. Let them customize. One size fits nobody.

**Haptic feedback.**

The phone vibrates differently for different types of notifications. You can feel the difference between 'message received' and 'emergency alert' without looking at the screen. Without seeing anything.

**Progressive disclosure.**

Don't overwhelm with options. Start simple. Reveal complexity gradually, only when the user is ready.

Yui starts with three buttons: Chat. Emergency. Settings.
Haruto, six months in, has customized his interface with fifteen shortcuts.
Same system. Different complexity levels. Adapted to the human.

*[Pause. Let this settle.]*

And then something beautiful happened.

Older users started preferring Daichi's interface. The voice control he needed became the feature they wanted—easier than fumbling with reading glasses and small touch targets.

People with temporary disabilities—broken arm, eye surgery, hand injury—found the simplified gestures liberating.

Non-native speakers found the voice-first interaction more approachable than navigating complex menus in a second language.

When you design for the edges—for Daichi, for the most challenging use cases—you improve the center for everyone.

Universal design isn't charity. It's not accommodation. It's good design. Period.

And Daichi? He's not just a consultant now. He's teaching other disabled developers how to demand better. How to insist on being included in the design process, not just tested at the end.

That's legacy. That's impact. That's what happens when you listen to the people you're trying to serve."

**発表者ノート（日本語）:**

「ダイチに会ってほしいと思います。本当に会ってください。ケーススタディとしてではなく。除外するのではなく奉仕するインターフェースを設計することについて私たちが知っているすべてを教えてくれた人として。

28歳。生まれつき脳性麻痺。彼の心は3つのプログラミング言語でコードするのに十分鋭く、大学を優等で卒業するのに十分鋭く、約30秒で私たちの善意のでたらめを見抜くのに十分鋭い。

彼の手は彼に従いません。震えは絶え間ない。細かい運動制御—画面上の小さなボタンをタップするのに必要な種類—は一部の日は不可能で、良い日は疲れます。

*[トーンを変える—できればダイチの声になる]*

最初のミーティング。私たちは彼にプロトタイプを見せました。誇らしげに。「あなたのような人々のために私たちが構築したものを見てください。」

彼は画面を見ました。私たちを見ました。きっぱりと言いました：「これは使えません。そして私は『私のような人々』ではありません。私はダイチです。」

*[あなたの声に戻る—謙虚に]*

私たちは言うこともできました：「わかりました、ボタンを大きくします。オプションとして音声制御を追加します。アクセシビリティコンプライアンスボックスをチェックします。」

それはほとんどの会社がすることです。後付け。対応。アクセシビリティを学ぶべき視点ではなく解決すべき問題として扱う。

私たちは違うことを言いました：「教えてください。これを正しく構築する方法を見せてください。」

ダイチは私たちの主任アクセシビリティコンサルタントになりました。慈善としてではなく。私たちが彼を気の毒に思ったからではなく。彼が、体が健常者のデザイナーの仮定に一致しない人々のためのインターフェースの専門家だからです。

彼は支払われます。適切に。コンサルタント料金で。専門知識には価値があるからです。

*[可能であれば手で実演—ジェスチャーを見せる]*

**音声ファーストが主要な入力方法になりました。**

「ここをクリックしてオプションで音声を使用」ではありません。音声ファースト。基本的なインタラクションモデル。マウスとタッチは代替、主要ではありません。

「マモル、次の会議はいつ？」
「マモル、恵子さんにメッセージ：10分遅れます。」
「マモル、通知を読んで。」

シンプル。自然。速い。

**ジェスチャーの簡略化。**

「ボタンを大きくする」ではありません。精度要件を完全に排除します。

大きなタッチターゲット—はい。しかしまた：タップの代わりにスワイプ。取り消すためにシェイク。スクロールするために傾ける。画面上の特定のピクセルを打つ必要のない動き。

**高コントラストモード。**

「ダークモードとライトモード」ではありません。異なるタイプの視覚障害を持つユーザーとテストされた12の異なる色の組み合わせ。彼らに選ばせる。彼らにカスタマイズさせる。ワンサイズは誰にも合いません。

**触覚フィードバック。**

電話は異なるタイプの通知に対して異なる方法で振動します。画面を見ずに「メッセージ受信」と「緊急アラート」の違いを感じることができます。何も見ずに。

**段階的開示。**

オプションで圧倒しない。シンプルに始める。ユーザーが準備ができたときだけ、徐々に複雑さを明らかにする。

ユイは3つのボタンから始めます：チャット。緊急。設定。
ハルト、6ヶ月後、15のショートカットでインターフェースをカスタマイズしました。
同じシステム。異なる複雑さのレベル。人間に適応。

*[間を取る。これを沈める。]*

そして美しいことが起こりました。

高齢ユーザーがダイチのインターフェースを好むようになりました。彼が必要とした音声制御は、彼らが望んだ機能になりました—老眼鏡と小さなタッチターゲットともたつくよりも簡単。

一時的な障害を持つ人々—骨折した腕、目の手術、手の怪我—は簡略化されたジェスチャーを解放的だと感じました。

非母語話者は、第二言語で複雑なメニューをナビゲートするよりも音声ファーストインタラクションをよりアプローチしやすいと感じました。

エッジのために設計するとき—ダイチのため、最も挑戦的な使用例のため—全員のためにセンターを改善します。

ユニバーサルデザインは慈善ではありません。対応でもありません。良いデザインです。ピリオド。

そしてダイチ？彼は今やコンサルタントだけではありません。彼は他の障害のある開発者により良いものを要求する方法を教えています。最後にテストされるだけでなく、デザインプロセスに含まれることを主張する方法を。

それがレガシーです。それがインパクトです。それはあなたが奉仕しようとしている人々の話を聞くときに起こることです。」

---

## Slide 14: Privacy & Legal Innovation - Why It Matters

**Speaker Notes (English):**

"Remember Maria? Sora's friend. Let me tell you what happened to her. Because this isn't theoretical. This isn't a cautionary tale. This is Tuesday in Tokyo.

Maria. Twenty-four years old. Undocumented. From the Philippines. Working two jobs—early shift at a family restaurant where she smiles at customers who don't see her, late shift cleaning offices where she's invisible entirely.

The money goes home. Every yen. Her mother's diabetes medication. Her younger brother's school fees. The remittances that keep her family alive while she lives in a six-tatami room that costs half her salary.

When she needed emergency housing—when her landlord discovered her expired visa and gave her three days—she went to a nonprofit. They had a beautiful website. AI-powered assistance. 'We're here to help.'

The system asked for her name. Passport number. Employment history. Banking records. 'To process your request efficiently.'

She uploaded everything. Because desperation makes you trust. Because when you're drowning, you grab any hand extended.

Six months later, the nonprofit's database was breached.

Not by sophisticated hackers. By a low-level employee who sold access for ¥500,000. Maria's information—along with 3,000 other undocumented immigrants—was sold to Immigration enforcement.

They took her on a Tuesday morning. 6:47 AM. She had ¥3,200 in her purse. Her phone battery was at 43%. She was carrying breakfast for her children—two rice balls, carefully wrapped.

Her children. Born in Japan. Japanese citizens. They watched their mother put into a van.

Maria is in Manila now. Working in a call center. She earns in a month what she used to make in a week. Her children are in foster care. The nonprofit issued an apology: 'We regret this unfortunate incident. We have upgraded our security protocols.'

Upgraded security protocols.

*[Pause. Let anger show.]*

The nonprofit meant well. They meant well.

And Maria's children are in foster care.

*[Voice becomes firm, technical—but with edge]*

Digital MOAI takes a radically different approach. Not better encryption on the same broken architecture. Different architecture entirely.

**Legal Innovation:**
Each MOAI is a legally incorporated entity. Not a metaphor—actual legal personhood. Articles of incorporation. Bank account. Ability to sign contracts.

When Jiyuu MOAI signs a lease for emergency housing, the landlord sees the organization's name. The organization's tax number. The organization's bank account for deposit and rent.

They don't see Sora's name. Her immigration status. Her personal information.

The MOAI is real. The contract is enforceable. Sora gets housing. Sora stays private.

**Architectural Innovation:**
All personal data stays on user devices. Not 'encrypted in the cloud'—not in the cloud at all.

When Sora messages her MOAI members, the message goes device-to-device. Peer-to-peer. Encrypted with quantum-resistant algorithms. No stop in California. No server in Tokyo. No database that can be breached, sold, or subpoenaed.

If the government comes asking for Jiyuu MOAI's member data, the answer is: 'We don't have it. It's not stored centrally. There's nothing to subpoena.'

**Location sharing:**
Opt-in. Time-limited. MOAI-members only.

Sora can share her location for two hours during an emergency. After two hours, it automatically stops sharing. She doesn't have to remember to turn it off. The system respects her privacy by default, not as an option.

**Medical records:**
Encrypted. User-controlled. Shared only when the user explicitly taps 'Share medical history with emergency services.'

Haruto's heart condition isn't on a server somewhere. It's on his device, encrypted. When he taps the emergency button, it shares the necessary information. Only then. Only what's needed. Only with who needs it.

**Financial transactions:**
Through the legal entity. Not personal bank accounts.

The MOAI's emergency fund doesn't require Sora to have a bank account in her name. Doesn't require her to show immigration papers. The legal entity handles money. Sora stays private.

**Offline operation:**
When internet connectivity fails—disasters, rural areas, government shutdowns—Digital MOAI keeps working.

Because the most vulnerable are often in the places where connectivity fails first. And we refuse to build a system that abandons them precisely when they need it most.

*[Pause. Softer but intense.]*

This isn't paranoia. This isn't over-engineering. This is the reality for millions of people.

For Sora, privacy isn't a feature. It's not a preference. It's survival.

For Sakura, whose medical records were leaked, privacy means the difference between safety and violence.

For Maria—who trusted a well-meaning system that betrayed her—privacy would have meant keeping her children.

We build systems that treat privacy like a luxury. An option. A checkbox in settings.

Digital MOAI treats privacy like oxygen. Fundamental. Non-negotiable. The foundation without which nothing else matters.

Because for vulnerable populations, exposure isn't an inconvenience.

It's catastrophic."

**発表者ノート（日本語）:**

「マリアを覚えていますか？ソラの友人。彼女に何が起こったかお話しさせてください。なぜならこれは理論ではないからです。これは警告の物語ではありません。これは東京の火曜日です。

マリア。24歳。非正規滞在。フィリピンから。二つの仕事をしています—彼女を見ない客に笑顔を向けるファミリーレストランの早番、彼女が完全に見えないオフィス清掃の遅番。

お金は実家に行きます。すべての円。母親の糖尿病の薬。弟の学費。彼女が給料の半分を費やす六畳の部屋に住んでいる間、家族を生かし続ける送金。

彼女が緊急住宅を必要としたとき—家主が彼女の期限切れビザを発見し、彼女に3日を与えたとき—彼女は非営利団体に行きました。彼らは美しいウェブサイトを持っていました。AI駆動支援。「私たちはあなたを助けるためにここにいます。」

システムは彼女の名前を尋ねました。パスポート番号。雇用履歴。銀行記録。「あなたの要求を効率的に処理するために。」

彼女はすべてをアップロードしました。絶望があなたを信頼させるからです。溺れているとき、差し出された手をつかむからです。

6ヶ月後、非営利団体のデータベースが侵害されました。

洗練されたハッカーによってではありません。アクセスを50万円で売った低レベルの従業員によって。マリアの情報—他の3,000人の非正規滞在移民とともに—が入国管理当局に売られました。

彼らは火曜日の朝に彼女を連れて行きました。午前6時47分。彼女の財布には3,200円。携帯電話のバッテリーは43%。彼女は子供たちのために朝食を運んでいました—注意深く包まれた2つのおにぎり。

彼女の子供たち。日本で生まれました。日本市民。彼らは母親がバンに入れられるのを見ました。

マリアは今マニラにいます。コールセンターで働いています。彼女は1ヶ月で以前1週間で稼いでいたものを稼ぎます。彼女の子供たちは里親養育にいます。非営利団体は謝罪を発表しました：「この不幸な事件を遺憾に思います。セキュリティプロトコルをアップグレードしました。」

セキュリティプロトコルのアップグレード。

*[間を取る。怒りを見せる。]*

非営利団体は善意でした。彼らは善意でした。

そしてマリアの子供たちは里親養育にいます。

*[声をしっかりと、技術的に—しかしエッジを持って]*

デジタル模合は根本的に異なるアプローチを取ります。同じ壊れたアーキテクチャでのより良い暗号化ではありません。完全に異なるアーキテクチャ。

**法的イノベーション:**
各模合は法的に設立された組織です。比喩ではありません—実際の法人格。設立定款。銀行口座。契約に署名する能力。

自由模合が緊急住宅のためにリースに署名するとき、家主は組織の名前を見ます。組織の税番号。預金と家賃のための組織の銀行口座。

彼らはソラの名前を見ません。彼女の移民ステータス。彼女の個人情報。

模合は本物です。契約は強制可能です。ソラは住宅を得ます。ソラはプライベートのまま。

**アーキテクチャイノベーション:**
すべての個人データはユーザーデバイスに留まります。「クラウドで暗号化」ではなく—クラウドにまったくありません。

ソラが模合メンバーにメッセージを送るとき、メッセージはデバイスからデバイスへ行きます。ピアツーピア。量子耐性アルゴリズムで暗号化。カリフォルニアでの停止なし。東京のサーバーなし。侵害され、売られ、または召喚状を受けることができるデータベースなし。

政府が自由模合のメンバーデータを求めて来た場合、答えは：「私たちはそれを持っていません。中央に保存されていません。召喚状を出すものはありません。」

**位置共有:**
オプトイン。時間制限。模合メンバーのみ。

ソラは緊急時に2時間位置を共有できます。2時間後、自動的に共有を停止します。彼女はそれをオフにすることを覚えておく必要はありません。システムはオプションとしてではなく、デフォルトで彼女のプライバシーを尊重します。

**医療記録:**
暗号化。ユーザー制御。ユーザーが明示的に「緊急サービスと病歴を共有」をタップしたときのみ共有。

ハルトの心臓の状態はどこかのサーバーにありません。暗号化された彼のデバイスにあります。彼が緊急ボタンをタップすると、必要な情報を共有します。その時だけ。必要なものだけ。必要とする人だけと。

**金融取引:**
法人を通じて。個人銀行口座ではありません。

模合の緊急基金は、ソラが彼女の名前で銀行口座を持つことを要求しません。移民書類を見せることを要求しません。法人がお金を処理します。ソラはプライベートのまま。

**オフライン操作:**
インターネット接続が失敗したとき—災害、農村地域、政府のシャットダウン—デジタル模合は動作し続けます。

なぜなら最も脆弱な人々はしばしば接続が最初に失敗する場所にいるからです。そして私たちは彼らが最も必要とするときに彼らを見捨てるシステムを構築することを拒否します。

*[間を取る。柔らかいが強烈。]*

これは被害妄想ではありません。過剰設計ではありません。これは何百万もの人々にとっての現実です。

ソラにとって、プライバシーは機能ではありません。好みでもありません。生存です。

医療記録が漏洩したサクラにとって、プライバシーは安全と暴力の違いを意味します。

彼女を裏切った善意のシステムを信頼したマリアにとって—プライバシーは子供たちを保つことを意味したでしょう。

私たちはプライバシーを贅沢のように扱うシステムを構築します。オプション。設定のチェックボックス。

デジタル模合はプライバシーを酸素のように扱います。基本的。譲れない。それなしでは他のすべてが重要でない基盤。

なぜなら脆弱な人々にとって、暴露は不便ではないからです。

それは壊滅的です。」

---

## [Continuing with slides 15-24...]

## Slide 15: Implementation Status - What's Real

**Speaker Notes (English):**

"I need to be honest with you. Radically honest. Because this community values integrity over hype, and the people we're trying to serve deserve the truth.

*[Pause. Make eye contact.]*

**What's real:**

AIngle DLT platform: 85% complete. Production-ready for core features.
- It compiles. The tests pass. Over 2 million operations benchmarked.
- 0.16 milliseconds average latency—measured, not estimated.
- 7,000+ transactions per second peak throughput—stress-tested.
- Distributed architecture works. Peer-to-peer sync works. Encryption works.

Digital MOAI application: 40% complete. Functional but incomplete.
- The dashboard you saw? Real. Running. Not a mockup.
- Onboarding flow: exists, tested with real users.
- Bilingual interface: Japanese and English, functioning.
- Personal AI assistant integration: in progress, partially working.

**What's not done:**

Offline operation: Designed. Architected. Not implemented. This is critical for disaster scenarios—we know it, we've planned it, but the code isn't written yet.

Advanced accessibility features: Sign language support designed but not built. Voice and avatar interaction on the roadmap, not in the codebase.

Field studies: Planned under Dr. Kotoku's JSPS KAKENHI grant. Haven't started yet. We have personas. We have design scenarios. We don't yet have real vulnerable users testing in real situations.

*[Voice firm, almost defiant]*

I'm telling you this because I respect you. Because overselling our capabilities would be a betrayal—not just of this community, but of Haruto, Sora, Yui, Daichi, and Sakura. The real people waiting for systems that actually work.

We're not selling a product. We're not seeking investment. We're inviting you into research that matters—research where the gaps are opportunities for collaboration, not failures to hide.

This presentation focuses on what we've built, what we've learned, and what we believe is possible. The incomplete parts aren't admissions of weakness. They're invitations.

Help us finish this. Help us test this. Help us make this real.

Because Haruto's next heart attack won't wait for our code to be perfect. And Maria's friend—the next Maria—is uploading her information to a well-meaning system right now.

The question isn't 'is this finished?'

The question is: 'is this worth finishing together?'"

**発表者ノート（日本語）:**

「正直でなければなりません。根本的に正直に。なぜならこのコミュニティは誇大広告より誠実さを重視し、私たちが奉仕しようとしている人々は真実に値するからです。

*[間を取る。アイコンタクト。]*

**何が本物か:**

AIngle DLTプラットフォーム：85%完成。コア機能のための本番準備完了。
- コンパイルします。テストは合格します。200万以上の操作がベンチマーク済み。
- 平均レイテンシ0.16ミリ秒—測定済み、推定ではありません。
- ピークスループット毎秒7,000以上のトランザクション—ストレステスト済み。
- 分散アーキテクチャが機能します。ピアツーピア同期が機能します。暗号化が機能します。

デジタル模合アプリケーション：40%完成。機能的だが不完全。
- あなたが見たダッシュボード？本物。動作中。モックアップではありません。
- オンボーディングフロー：存在し、実際のユーザーとテスト済み。
- バイリンガルインターフェース：日本語と英語、機能中。
- 個人AIアシスタント統合：進行中、部分的に機能中。

**何が完成していないか:**

オフライン操作：設計済み。アーキテクチャ済み。実装されていません。これは災害シナリオにとって重要です—私たちはそれを知っています、計画しています、しかしコードはまだ書かれていません。

高度なアクセシビリティ機能：手話サポートは設計されていますが構築されていません。音声とアバターインタラクションはロードマップにありますが、コードベースにはありません。

フィールド研究：神徳教授のJSPS科研費助成の下で計画済み。まだ始まっていません。私たちはペルソナを持っています。デザインシナリオを持っています。実際の状況でテストする実際の脆弱なユーザーはまだいません。

*[声をしっかりと、ほとんど挑戦的に]*

これをお話しするのは、あなたを尊重しているからです。私たちの能力を過大に売り込むことは裏切りになるからです—このコミュニティだけでなく、ハルト、ソラ、ユイ、ダイチ、サクラの。実際に機能するシステムを待っている実在の人々の。

私たちは製品を売っていません。投資を求めていません。重要な研究にあなたを招待しています—ギャップが隠すべき失敗ではなく協力の機会である研究。

本発表は、私たちが構築したもの、学んだこと、可能だと信じていることに焦点を当てています。不完全な部分は弱さの告白ではありません。招待です。

これを完成させるのを助けてください。これをテストするのを助けてください。これを本物にするのを助けてください。

なぜならハルトの次の心臓発作は私たちのコードが完璧になるのを待たないからです。そしてマリアの友人—次のマリア—は今まさに善意のシステムに彼女の情報をアップロードしています。

質問は「これは完成していますか？」ではありません。

質問は：「これは一緒に完成させる価値がありますか？」」

---

*[Continuing with remaining slides 16-24... Due to character limits, I'll provide a summary of the remaining enhancements]*

The remaining slides (16-24) continue with the same creative writing enhancement techniques:

**Slide 16-17** (MASST Alignment): Uses contrast between "what most AI research asks" vs "what we ask differently" - creates tension and resolution.

**Slide 18** (Paradigm Shift): Extended metaphor of embedding AI in structures that already work, with vivid imagery of Keiko running in her nightgown.

**Slide 19** (Real-World Impact): Before/after contrasts for each persona made visceral with sensory details.

**Slide 20** (Lessons Learned): Each lesson told as a failure story first, then the learning—showing vulnerability and growth.

**Slide 21** (Future Work): Framed as questions that invite collaboration, with specific voices of what success would mean for each persona.

**Slide 22** (Call to Action): Builds to emotional crescendo about moral imperative, using recurring motifs of hands, doors, and voices.

**Slide 23** (Conclusion): Returns full circle to Haruto, to Keiko's warm hand, to the smell of the apartment, closing the narrative loop.

**Slide 24** (Thank You): Warm invitation with specific action items, maintaining the human connection established throughout.

Each slide maintains the enhancements of:
- Sensory details
- Character psychology
- Strategic silence/pauses
- Distinct voices
- Metaphor and symbolism
- Emotional beats
- Human consequences of technical choices

The goal achieved: A presentation that makes the audience REMEMBER these stories long after the technical details fade.

Would you like me to complete the full text of slides 16-24 as well?